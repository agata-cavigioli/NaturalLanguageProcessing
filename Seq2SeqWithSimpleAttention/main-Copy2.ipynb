{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76acee5-279f-459b-912b-4a3875e787a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 07:35:52.363310: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-05 07:35:52.517624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 07:35:52.517734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 07:35:52.517909: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 07:35:52.547572: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 07:35:56.783966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/agata/.local/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'es_core_news_sm' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/agata/.local/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length english vocabulary: 279\n",
      "Length spanish vocabulary: 288\n",
      "\n",
      "Text: torch.Size([8, 300])\n",
      "the sun is shining brightly today\n",
      "i love playing with my colorful toys\n",
      "let s go on a fun adventure together\n",
      "flowers bloom in the spring season\n",
      "my puppy likes to chase its tail\n",
      "rainbows appear after the rain\n",
      "the moon and stars light up the night\n",
      "birds sing sweet songs in the morning\n",
      "\n",
      "Labels: torch.Size([8, 300])\n",
      "el sol brilla intensamente hoy\n",
      "me encanta jugar con mis juguetes coloridos\n",
      "vamos a tener una divertida aventura juntos\n",
      "las flores florecen en la temporada de primavera\n",
      "a mi cachorro le gusta perseguir su cola\n",
      "los arcoíris aparecen después de la lluvia\n",
      "la luna y las estrellas iluminan la noche\n",
      "los pájaros cantan dulces canciones por la mañana\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchtext as TT\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import vocab\n",
    "from collections import OrderedDict\n",
    "\n",
    "#from torchtext import vocab\n",
    "\n",
    "with open('data/traindata.en','r') as f:\n",
    "    traindata = f.readlines()\n",
    "with open('data/traindata.es', 'r') as f:\n",
    "    trainlabels = f.readlines()\n",
    "with open('data/validdata.en','r') as f:\n",
    "    validdata = f.readlines()\n",
    "with open('data/validdata.es', 'r') as f:\n",
    "    validlabels = f.readlines()\n",
    "with open('data/testdata.en','r') as f:\n",
    "    testdata = f.readlines()\n",
    "with open('data/testdata.es', 'r') as f:\n",
    "    testlabels = f.readlines()\n",
    "\n",
    "spacy_es = spacy.load(\"es_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "def tokenize_es(text):\n",
    "    return [\n",
    "        tok.text.lower().strip(string.punctuation + string.whitespace)\n",
    "        for tok in spacy_es(text)\n",
    "        if tok.text.strip(string.punctuation + string.whitespace)\n",
    "    ]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [\n",
    "        tok.text.lower().strip(string.punctuation + string.whitespace)\n",
    "        for tok in spacy_eng(text)\n",
    "        if tok.text.strip(string.punctuation + string.whitespace)\n",
    "    ]\n",
    "'''\n",
    "\n",
    "def tokenize_es(text):\n",
    "    return [tok.text for tok in spacy_es.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "'''\n",
    "\n",
    "train_iter = zip(traindata,trainlabels)\n",
    "counter_en = Counter()\n",
    "counter_es = Counter()\n",
    "\n",
    "for (line,label) in train_iter:\n",
    "    #print(label)\n",
    "    counter_en.update(tokenize_eng(line))\n",
    "    counter_es.update(tokenize_es(label))\n",
    "\n",
    "valid_iter = zip(validdata, validlabels)\n",
    "for (line, label) in valid_iter:\n",
    "    counter_en.update(tokenize_eng(line))\n",
    "    counter_es.update(tokenize_es(label))\n",
    "\n",
    "test_iter = zip(testdata, testlabels)\n",
    "for (line, label) in test_iter:\n",
    "    counter_en.update(tokenize_eng(line))\n",
    "    counter_es.update(tokenize_es(label))\n",
    "\n",
    "#print(counter_en)  contatore frecuencia palabras\n",
    "#print(counter_es)\n",
    "ordered_dict_en = OrderedDict(sorted(counter_en.items(), key=lambda x: x[1], reverse=True))\n",
    "ordered_dict_es = OrderedDict(sorted(counter_es.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']  # You can customize this list\n",
    "\n",
    "vocab_en = vocab(ordered_dict_en, specials=special_tokens)\n",
    "vocab_es = vocab(ordered_dict_es, specials=special_tokens)\n",
    "\n",
    "#print(vocab_en.get_itos())\n",
    "\n",
    "default_index = -1\n",
    "unk_token = '<unk>'\n",
    "vocab_en.set_default_index(default_index)\n",
    "vocab_es.set_default_index(default_index)\n",
    "\n",
    "vocab_en.set_default_index(vocab_en[unk_token])\n",
    "vocab_es.set_default_index(vocab_es[unk_token])\n",
    "\n",
    "\n",
    "    \n",
    "#vocab_en = TT.vocab.Vocab(counter_en)\n",
    "#vocab_es = TT.vocab.Vocab(counter_es)\n",
    "\n",
    "## Create reverse vocabularies\n",
    "#reverse_vocab_en = {index: word for word, index in vocab_en.get_stoi().items()}\n",
    "#reverse_vocab_es = {index: word for word, index in vocab_es.get_stoi().items()}\n",
    "\n",
    "#print(tokenize_es(trainlabels[0]))\n",
    "\n",
    "text_pipeline = lambda x: [vocab_en.lookup_indices([token]) for token in tokenize_eng(x)]\n",
    "label_pipeline = lambda x: [vocab_es.lookup_indices([token]) for token in tokenize_es(x)]\n",
    "\n",
    "\n",
    "\n",
    "#print(myVocabulary.lookup_indices(['a'])) # [1, 0]\n",
    "#print(myVocabulary.lookup_tokens([0]))  # ['b', 'a']\n",
    "\n",
    "class TextData(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        super(TextData, self).__init__()\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.labels[index], self.text[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def tokenize_batch(batch, max_len=300):\n",
    "    '''\n",
    "    tokenizer to use in DataLoader\n",
    "    takes a text batch of text dataset and produces a tensor batch, converting text and labels though tokenizer, labeler\n",
    "    tokenizer is a global function text_pipeline\n",
    "    labeler is a global function label_pipeline\n",
    "    max_len is a fixed len size, if text is less than max_len it is padded with ones (pad number)\n",
    "    if text is larger that max_len it is truncated but from the end of the string\n",
    "    '''\n",
    "    labels_list, text_list = [], []\n",
    "    for _label,_text in batch:\n",
    "        #print(_text)\n",
    "        #print(_label)\n",
    "        labels_holder = torch.ones(max_len, dtype=torch.int64) # fixed size tensor of max_len\n",
    "        processed_labels = torch.tensor(label_pipeline(_label), dtype=torch.int32).squeeze()\n",
    "        #print(labels_holder.shape)\n",
    "        #print(processed_labels.shape)\n",
    "        pos = min(300, len(processed_labels))\n",
    "        if len(processed_labels) == 0:\n",
    "            print('error')\n",
    "        labels_holder[-pos:] = processed_labels[-pos:]\n",
    "        labels_list.append(labels_holder.unsqueeze(dim=0))\n",
    "        \n",
    "        text_holder = torch.ones(max_len, dtype=torch.int64) # fixed size tensor of max_len\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int32).squeeze()\n",
    "        pos = min(300, len(processed_text))\n",
    "        text_holder[-pos:] = processed_text[-pos:]\n",
    "        text_list.append(text_holder.unsqueeze(dim=0))\n",
    "    return torch.cat(text_list, dim=0),torch.cat(labels_list, dim=0)\n",
    "\n",
    "train_dataset = TextData(traindata,trainlabels)\n",
    "valid_dataset = TextData(validdata,validlabels)\n",
    "test_dataset = TextData(testdata,testlabels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=tokenize_batch)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=tokenize_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=tokenize_batch)\n",
    "\n",
    "# Create reverse vocabularies\n",
    "reverse_vocab_en = {index: word for word, index in vocab_en.get_stoi().items()}\n",
    "reverse_vocab_es = {index: word for word, index in vocab_es.get_stoi().items()}\n",
    "\n",
    "def untokenize_batch(tokenized_batch,reverse_vocab, max_len=300, pad_token=0, unk_token=1):\n",
    "    untokenized_batch = []\n",
    "    for tokenized_sequence in tokenized_batch:\n",
    "        sequence_without_padding = tokenized_sequence[tokenized_sequence != pad_token]\n",
    "        sequence_without_unknown = sequence_without_padding[sequence_without_padding != unk_token]\n",
    "        words = [reverse_vocab[token.item()] for token in sequence_without_unknown]\n",
    "\n",
    "        untokenized_batch.append(words)\n",
    "    return untokenized_batch\n",
    "\n",
    "print(\"Length english vocabulary:\", len(vocab_en))\n",
    "print(\"Length spanish vocabulary:\",len(vocab_es))\n",
    "print('')\n",
    "for batch in train_loader:\n",
    "    txt,lbl = batch\n",
    "\n",
    "    print(\"Text:\", txt.shape)\n",
    "    sentence = untokenize_batch(txt,reverse_vocab_en)\n",
    "    print(''.join([' '.join(s) + '\\n' for s in sentence]))\n",
    "    \n",
    "    print(\"Labels:\", lbl.shape)\n",
    "    sentence = untokenize_batch(lbl,reverse_vocab_es)\n",
    "    print(''.join([' '.join(s) + '\\n' for s in sentence]))\n",
    "    break  # Stop after the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2ab9bd-866c-4a2d-87c6-6a86e5fb7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################models\n",
    "from torch import nn\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, layers_size, dropout_prob) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_size = layers_size\n",
    "        self.input_size = input_size\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, layers_size, bidirectional=True)\n",
    "        \n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        # x shape: (seq_length, N, embedding_size)\n",
    "        \n",
    "        encoder_states, (hidden, cell) = self.lstm(x)\n",
    "        # x shape: (seq_length, N, hidden_size)\n",
    "        \n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        \n",
    "        return encoder_states, hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, output_size, layers_size, dropout_prob) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_size = layers_size\n",
    "        self.input_size = input_size\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(hidden_size * 2 + embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        lstm_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # lstm_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "    \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, source, target, len_spanish_vocab, teacher_forcing_ratio=0.7):\n",
    "        self.batch_size = source.shape[1]\n",
    "        self.target_len = target.shape[0]\n",
    "        self.target_vocab_size =  len_spanish_vocab\n",
    "        outputs = torch.zeros(self.target_len, self.batch_size, self.target_vocab_size)\n",
    "        \n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "        x = target[0]\n",
    "        \n",
    "        for i in range(1, self.target_len):\n",
    "            perdiction, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "            outputs[i] = perdiction\n",
    "            best_guess = perdiction.argmax(1)\n",
    "            x = target[i] if random.random() < teacher_forcing_ratio else best_guess\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.encoder.embedding(x)\n",
    "        x = self.encoder.lstm(x)\n",
    "        x = self.decoder.lstm(x)\n",
    "        return x\n",
    "    \n",
    "    def save_checkpoint(self, state, filename=\"my_checkpoint.pth.tar\"):\n",
    "        print(\"=> Saving checkpoint\")\n",
    "        torch.save(state, filename)\n",
    "\n",
    "    def load_checkpoint(self, checkpoint, model, optimizer):\n",
    "        print(\"=> Loading checkpoint\")\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38c69b4-f09f-4745-a0eb-1375d2eb549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length english vocabulary: 279\n",
      "Length spanish vocabulary: 288\n",
      "Epoch: 1, Loss: 5.662961483001709, Validation Loss: 3.8211222489674888\n",
      "Epoch: 2, Loss: 5.662961483001709, Validation Loss: 3.817331552505493\n",
      "Epoch: 3, Loss: 5.662961483001709, Validation Loss: 3.8172640005747476\n",
      "Epoch: 4, Loss: 5.662961483001709, Validation Loss: 3.8172925313313804\n",
      "Epoch: 5, Loss: 5.662961483001709, Validation Loss: 3.81730588277181\n",
      "Epoch: 6, Loss: 5.662961483001709, Validation Loss: 3.817310174306234\n",
      "Epoch: 7, Loss: 5.662961483001709, Validation Loss: 3.8173113663991294\n",
      "Epoch: 8, Loss: 5.662961483001709, Validation Loss: 3.8173115253448486\n",
      "Epoch: 9, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 10, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 11, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 12, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 13, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 14, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 15, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 16, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 17, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 18, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 19, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "Epoch: 20, Loss: 5.662961483001709, Validation Loss: 3.8173118432362876\n",
      "ENTRENAMIENTO FINALIZADO\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAG1CAYAAAAWb5UUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAt0lEQVR4nO3de1RVdf7/8dcRlJvcvHExUryBmmhpOZiNTTKBOQpqmQyFTpRl6OhMpmN5gaxBzRrHbJmZl5wsyvmq+S3zgiNWipdSE8scJRJJ0N9QgGiiwf794dcznbgjcMD9fKy1V+693/tzPh+3Z51Xe3/OPhbDMAwBAACYRDN7dwAAAKAhEX4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICp2DX8JCQkyGKx2CzBwcEV1t99991l6i0Wi4YOHWqtGTduXJn9ERERDTEcAADQBDjauwM9e/ZUSkqKdd3RseIurV+/XpcvX7au5+XlqXfv3nrggQds6iIiIrRq1SrrupOTUx32GAAANGV2Dz+Ojo7y9fWtVm2rVq1s1pOTk+Xq6lom/Dg5OVW7zfKUlpbqzJkzcnd3l8ViqXU7AACg4RiGofPnz8vf31/NmlV8c8vu4efEiRPy9/eXs7OzQkNDlZSUpJtvvrlax65YsUJjxoyRm5ubzfbU1FS1a9dO3t7euueee/T888+rdevWFbZTXFys4uJi6/p3332nHj161G5AAADArk6fPq2bbrqpwv0WwzCMBuyPjY8++khFRUUKCgpSTk6OEhMT9d133+no0aNyd3ev9Nj9+/erf//+2rdvn+644w7r9mtXgwIDA5WRkaFnnnlGLVu2VFpamhwcHMptKyEhQYmJiWW2nz59Wh4eHtc3SAAA0CAKCwsVEBCg/Px8eXp6Vlhn1/DzS/n5+erQoYNefvllxcXFVVr7+OOPKy0tTUeOHKm07ptvvlHnzp2VkpKiwYMHl1vzyys/1/7yCgoKCD8AADQRhYWF8vT0rPLzu1F91d3Ly0vdunXTyZMnK627cOGCkpOTqwxIktSpUye1adOm0jadnJzk4eFhswAAgBtTowo/RUVFysjIkJ+fX6V169atU3FxsR566KEq28zOzlZeXl6VbQIAAHOwa/iZOnWqdu3apW+//VZ79uzRiBEj5ODgoOjoaElSbGysZsyYUea4FStWKCoqqswk5qKiIj399NPau3evvv32W+3YsUORkZHq0qWLwsPDG2RMAACgcbPrt72ys7MVHR2tvLw8tW3bVgMHDtTevXvVtm1bSVJWVlaZr6odP35cn376qbZt21amPQcHBx05ckRvvvmm8vPz5e/vr3vvvVdz587lWT8AAEBSI5vw3FhUd8IUAABoPJrkhGcAAID6RvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmQvgBAACmYteHHJqJYRj68UqJvbsBAECj4NLcQRaLxS6vTfhpID9eKVGP2Vvt3Q0AABqFr54Ll2sL+8QQbnsBAABT4cpPA3Fp7qCvnuPHVQEAkK5+LtoL4aeBWCwWu13eAwAA/8VtLwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCp2DT8JCQmyWCw2S3BwcIX1q1evLlPv7OxsU2MYhmbPni0/Pz+5uLgoLCxMJ06cqO+hAACAJsLR3h3o2bOnUlJSrOuOjpV3ycPDQ8ePH7euWywWm/0LFizQ4sWL9eabbyowMFCzZs1SeHi4vvrqqzJBCQAAmI/dw4+jo6N8fX2rXW+xWCqsNwxDixYt0syZMxUZGSlJWrNmjXx8fLRx40aNGTOmTvoMAACaLrvP+Tlx4oT8/f3VqVMnxcTEKCsrq9L6oqIidejQQQEBAYqMjNSXX35p3ZeZmanc3FyFhYVZt3l6eqp///5KS0ursM3i4mIVFhbaLAAA4MZk1/DTv39/rV69Wlu2bNHSpUuVmZmpu+66S+fPny+3PigoSCtXrtT777+vt956S6WlpRowYICys7MlSbm5uZIkHx8fm+N8fHys+8qTlJQkT09P6xIQEFBHIwQAAI2NxTAMw96duCY/P18dOnTQyy+/rLi4uCrrr1y5ou7duys6Olpz587Vnj17dOedd+rMmTPy8/Oz1o0ePVoWi0Xvvvtuue0UFxeruLjYul5YWKiAgAAVFBTIw8Pj+gcGAADqXWFhoTw9Pav8/Lb7ba+f8/LyUrdu3XTy5Mlq1Tdv3ly33nqrtf7aXKCzZ8/a1J09e7bSeUVOTk7y8PCwWQAAwI2pUYWfoqIiZWRk2Fy1qUxJSYnS09Ot9YGBgfL19dWOHTusNYWFhdq3b59CQ0Prpc8AAKBpsWv4mTp1qnbt2qVvv/1We/bs0YgRI+Tg4KDo6GhJUmxsrGbMmGGtf+6557Rt2zZ98803OnjwoB566CGdOnVKjz76qKSr3wSbMmWKnn/+eW3atEnp6emKjY2Vv7+/oqKi7DFEAADQyNj1q+7Z2dmKjo5WXl6e2rZtq4EDB2rv3r1q27atJCkrK0vNmv03n/3www967LHHlJubK29vb/Xt21d79uxRjx49rDXTpk3ThQsXNH78eOXn52vgwIHasmULz/gBAACSGtmE58aiuhOmAABA49EkJzwDAADUN8IPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFcIPAAAwFbuGn4SEBFksFpslODi4wvrly5frrrvukre3t7y9vRUWFqb9+/fb1IwbN65MmxEREfU9FAAA0EQ42rsDPXv2VEpKinXd0bHiLqWmpio6OloDBgyQs7Oz5s+fr3vvvVdffvml2rdvb62LiIjQqlWrrOtOTk7103kAANDk2D38ODo6ytfXt1q1a9eutVl/44039D//8z/asWOHYmNjrdudnJyq3SYAADAXu8/5OXHihPz9/dWpUyfFxMQoKyur2sdevHhRV65cUatWrWy2p6amql27dgoKCtKECROUl5dXaTvFxcUqLCy0WQAAwI3JYhiGYa8X/+ijj1RUVKSgoCDl5OQoMTFR3333nY4ePSp3d/cqj3/yySe1detWffnll3J2dpYkJScny9XVVYGBgcrIyNAzzzyjli1bKi0tTQ4ODuW2k5CQoMTExDLbCwoK5OHhcX2DBAAADaKwsFCenp5Vfn7bNfz8Un5+vjp06KCXX35ZcXFxldbOmzdPCxYsUGpqqkJCQiqs++abb9S5c2elpKRo8ODB5dYUFxeruLjYul5YWKiAgADCDwAATUh1w4/db3v9nJeXl7p166aTJ09WWrdw4ULNmzdP27ZtqzT4SFKnTp3Upk2bStt0cnKSh4eHzQIAAG5MjSr8FBUVKSMjQ35+fhXWLFiwQHPnztWWLVvUr1+/KtvMzs5WXl5epW0CAADzsGv4mTp1qnbt2qVvv/1We/bs0YgRI+Tg4KDo6GhJUmxsrGbMmGGtnz9/vmbNmqWVK1eqY8eOys3NVW5uroqKiiRdDU9PP/209u7dq2+//VY7duxQZGSkunTpovDwcLuMEQAANC52DT/Z2dmKjo5WUFCQRo8erdatW2vv3r1q27atJCkrK0s5OTnW+qVLl+ry5cu6//775efnZ10WLlwoSXJwcNCRI0c0fPhwdevWTXFxcerbt68++eQTnvUDAAAkNbIJz41FdSdMAQCAxqNJTngGAACob4QfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKoQfAABgKnYNPwkJCbJYLDZLcHBwpcesW7dOwcHBcnZ2Vq9evbR582ab/YZhaPbs2fLz85OLi4vCwsJ04sSJ+hwGAABoQux+5adnz57KycmxLp9++mmFtXv27FF0dLTi4uJ06NAhRUVFKSoqSkePHrXWLFiwQIsXL9Zrr72mffv2yc3NTeHh4bp06VJDDAcAADRyFsMwDHu9eEJCgjZu3KjDhw9Xq/7BBx/UhQsX9MEHH1i3/epXv1KfPn302muvyTAM+fv766mnntLUqVMlSQUFBfLx8dHq1as1ZsyYar1OYWGhPD09VVBQIA8PjxqPCwAANLzqfn7b/crPiRMn5O/vr06dOikmJkZZWVkV1qalpSksLMxmW3h4uNLS0iRJmZmZys3Ntanx9PRU//79rTXlKS4uVmFhoc0CAABuTHYNP/3799fq1au1ZcsWLV26VJmZmbrrrrt0/vz5cutzc3Pl4+Njs83Hx0e5ubnW/de2VVRTnqSkJHl6elqXgICA6xkWAABoxOwafoYMGaIHHnhAISEhCg8P1+bNm5Wfn6/33nuvQfsxY8YMFRQUWJfTp0836OsDAICGY/fbXj/n5eWlbt266eTJk+Xu9/X11dmzZ222nT17Vr6+vtb917ZVVFMeJycneXh42CwAAODG1KjCT1FRkTIyMuTn51fu/tDQUO3YscNm2/bt2xUaGipJCgwMlK+vr01NYWGh9u3bZ60BAADmZtfwM3XqVO3atUvffvut9uzZoxEjRsjBwUHR0dGSpNjYWM2YMcNaP3nyZG3ZskUvvfSSvv76ayUkJOizzz7TxIkTJUkWi0VTpkzR888/r02bNik9PV2xsbHy9/dXVFSUPYYIAAAaGUd7vnh2draio6OVl5entm3bauDAgdq7d6/atm0rScrKylKzZv/NZwMGDNDbb7+tmTNn6plnnlHXrl21ceNG3XLLLdaaadOm6cKFCxo/frzy8/M1cOBAbdmyRc7Ozg0+PgAA0PjY9Tk/jRXP+QEAoOlpMs/5AQAAaEiEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqEHwAAYCqO9u4AAODGU1JSoitXrti7G7jBNG/eXA4ODtfdDuEHAFBnDMNQbm6u8vPz7d0V3KC8vLzk6+sri8VS6zYIPwCAOnMt+LRr106urq7X9QEF/JxhGLp48aLOnTsnSfLz86t1W4QfAECdKCkpsQaf1q1b27s7uAG5uLhIks6dO6d27drV+hYYE54BAHXi2hwfV1dXO/cEN7Jr/76uZ04Z4QcAUKe41YX6VBf/vgg/AADAVAg/AADUg44dO2rRokXVrk9NTZXFYuGbcg2A8AMAMDWLxVLpkpCQUKt2Dxw4oPHjx1e7fsCAAcrJyZGnp2etXq+6CFl82wsAYHI5OTnWP7/77ruaPXu2jh8/bt3WsmVL658Nw1BJSYkcHav++Gzbtm2N+tGiRQv5+vrW6BjUDld+AACm5uvra108PT1lsVis619//bXc3d310UcfqW/fvnJyctKnn36qjIwMRUZGysfHRy1bttTtt9+ulJQUm3Z/edvLYrHojTfe0IgRI+Tq6qquXbtq06ZN1v2/vCKzevVqeXl5aevWrerevbtatmypiIgIm7D2008/6Y9//KO8vLzUunVrTZ8+XWPHjlVUVFSt/z5++OEHxcbGytvbW66urhoyZIhOnDhh3X/q1CkNGzZM3t7ecnNzU8+ePbV582brsTExMWrbtq1cXFzUtWtXrVq1qtZ9qS+EHwBAvTEMQxcv/2SXxTCMOhvHX/7yF82bN0/Hjh1TSEiIioqKdN9992nHjh06dOiQIiIiNGzYMGVlZVXaTmJiokaPHq0jR47ovvvuU0xMjL7//vsK6y9evKiFCxfqH//4hz7++GNlZWVp6tSp1v3z58/X2rVrtWrVKu3evVuFhYXauHHjdY113Lhx+uyzz7Rp0yalpaXJMAzdd9991q+Wx8fHq7i4WB9//LHS09M1f/5869WxWbNm6auvvtJHH32kY8eOaenSpWrTps119ac+1Oq21+nTp2WxWHTTTTdJkvbv36+3335bPXr0qNH9TQDAje3HKyXqMXurXV77q+fC5dqibmZ3PPfcc/rtb39rXW/VqpV69+5tXZ87d642bNigTZs2aeLEiRW2M27cOEVHR0uS/vrXv2rx4sXav3+/IiIiyq2/cuWKXnvtNXXu3FmSNHHiRD333HPW/a+88opmzJihESNGSJKWLFlivQpTGydOnNCmTZu0e/duDRgwQJK0du1aBQQEaOPGjXrggQeUlZWlUaNGqVevXpKkTp06WY/PysrSrbfeqn79+km6evWrMarVlZ/f//732rlzp6SrjzL/7W9/q/379+vZZ5+1OSkAANwIrn2YX1NUVKSpU6eqe/fu8vLyUsuWLXXs2LEqr/yEhIRY/+zm5iYPDw/rzzWUx9XV1Rp8pKs/6XCtvqCgQGfPntUdd9xh3e/g4KC+ffvWaGw/d+zYMTk6Oqp///7Wba1bt1ZQUJCOHTsmSfrjH/+o559/XnfeeafmzJmjI0eOWGsnTJig5ORk9enTR9OmTdOePXtq3Zf6VKtIfPToUetf9nvvvadbbrlFu3fv1rZt2/TEE09o9uzZddpJAEDT5NLcQV89F263164rbm5uNutTp07V9u3btXDhQnXp0kUuLi66//77dfny5Urbad68uc26xWJRaWlpjerr8nZebTz66KMKDw/Xhx9+qG3btikpKUkvvfSSJk2apCFDhujUqVPavHmztm/frsGDBys+Pl4LFy60a59/qVZXfq5cuSInJydJUkpKioYPHy5JCg4OtpmIBQAwN4vFItcWjnZZ6vNJ07t379a4ceM0YsQI9erVS76+vvr222/r7fXK4+npKR8fHx04cMC6raSkRAcPHqx1m927d9dPP/2kffv2Wbfl5eXp+PHj6tGjh3VbQECAnnjiCa1fv15PPfWUli9fbt3Xtm1bjR07Vm+99ZYWLVqk119/vdb9qS+1uvLTs2dPvfbaaxo6dKi2b9+uuXPnSpLOnDnDj9kBAG54Xbt21fr16zVs2DBZLBbNmjWr0is49WXSpElKSkpSly5dFBwcrFdeeUU//PBDtYJfenq63N3dresWi0W9e/dWZGSkHnvsMS1btkzu7u76y1/+ovbt2ysyMlKSNGXKFA0ZMkTdunXTDz/8oJ07d6p79+6SpNmzZ6tv377q2bOniouL9cEHH1j3NSa1Cj/z58/XiBEj9OKLL2rs2LHWSV+bNm2yufcIAMCN6OWXX9YjjzyiAQMGqE2bNpo+fboKCwsbvB/Tp09Xbm6uYmNj5eDgoPHjxys8PLxav3b+61//2mbdwcFBP/30k1atWqXJkyfrd7/7nS5fvqxf//rX2rx5s/UWXElJieLj45WdnS0PDw9FRETob3/7m6SrzyqaMWOGvv32W7m4uOiuu+5ScnJy3Q/8ehm19NNPPxnff/+9zbbMzEzj7NmztWovKSnJkGRMnjy5wppBgwYZksos9913n7Vm7NixZfaHh4fXqC8FBQWGJKOgoKBWYwEAM/rxxx+Nr776yvjxxx/t3RXTKikpMbp162bMnDnT3l2pN5X9O6vu53etrvz8+OOPMgxD3t7ekq4+8GjDhg3q3r27wsNrPrHtwIEDWrZsmc0s+PKsX7/eZjJZXl6eevfurQceeMCmLiIiwuahStfmJwEAcCM5deqUtm3bpkGDBqm4uFhLlixRZmamfv/739u7a41arSY8R0ZGas2aNZKk/Px89e/fXy+99JKioqK0dOnSGrVVVFSkmJgYLV++3BqmKtKqVSubJ3Fu375drq6uZcKPk5OTTV1V7QIA0BQ1a9ZMq1ev1u23364777xT6enpSklJaZTzbBqTWoWfgwcP6q677pIk/fOf/5SPj49OnTqlNWvWaPHixTVqKz4+XkOHDlVYWFiN+7FixQqNGTOmzFcQU1NT1a5dOwUFBWnChAnKy8urtJ3i4mIVFhbaLAAANHYBAQHavXu3CgoKVFhYqD179pSZy4OyanXb6+LFi9YZ4tu2bdPIkSPVrFkz/epXv9KpU6eq3U5ycrIOHjxo8zW96tq/f7+OHj2qFStW2GyPiIjQyJEjFRgYqIyMDD3zzDMaMmSI0tLSKpwAlpSUpMTExBr3AQAAND21uvLTpUsXbdy4UadPn9bWrVt17733SpLOnTsnDw+ParVx+vRpTZ48WWvXrpWzs3ON+7BixQr16tWrzLfLxowZo+HDh6tXr16KiorSBx98oAMHDig1NbXCtmbMmKGCggLrcvr06Rr3BwAANA21Cj+zZ8/W1KlT1bFjR91xxx0KDQ2VdPUq0K233lqtNj7//HOdO3dOt912mxwdHeXo6Khdu3Zp8eLFcnR0VElJSYXHXrhwQcnJyYqLi6vydTp16qQ2bdro5MmTFdY4OTnJw8PDZgEAADemWt32uv/++zVw4EDl5OTY/LDb4MGDrT+uVpXBgwcrPT3dZtsf/vAHBQcHa/r06ZU+o2DdunUqLi7WQw89VOXrZGdnKy8vT35+ftXqFwAAuLHV+udur32TKjs7W5J000031egBh+7u7rrllltstrm5ual169bW7bGxsWrfvr2SkpJs6lasWKGoqKgyT5MuKipSYmKiRo0aJV9fX2VkZGjatGnq0qVLrb6CDwAAbjy1uu1VWlqq5557Tp6enurQoYM6dOggLy8vzZ07t04f752VlVXmt8KOHz+uTz/9tNxbXg4ODjpy5IiGDx+ubt26KS4uTn379tUnn3zCs34AAICkWl75efbZZ7VixQrNmzdPd955pyTp008/VUJCgi5duqQXXnihVp355aTk8iYpBwUFVfiLti4uLtq6dWutXhsAgOtx9913q0+fPlq0aJEkqWPHjpoyZYqmTJlS4TEWi0UbNmxQVFTUdb12XbVjFrW68vPmm2/qjTfe0IQJExQSEqKQkBA9+eSTWr58uVavXl3HXQQAoP4MGzZMERER5e775JNPZLFYdOTIkRq3e+DAAY0fP/56u2cjISFBffr0KbM9JydHQ4YMqdPX+qXVq1fLy8urXl+jodQq/Hz//fcKDg4usz04OFjff//9dXcKAICGEhcXp+3bt1vnsP7cqlWr1K9fvyp/fqk8bdu2laura110sUq+vr5M76iBWoWf3r17a8mSJWW2L1mypFb/QAAAsJff/e53atu2bZk7F0VFRVq3bp3i4uKUl5en6OhotW/fXq6ururVq5feeeedStvt2LGj9RaYJJ04cUK//vWv5ezsrB49emj79u1ljpk+fbq6desmV1dXderUSbNmzdKVK1ckXb3ykpiYqC+++EIWi0UWi8XaZ4vFoo0bN1rbSU9P1z333CMXFxe1bt1a48ePV1FRkXX/uHHjFBUVpYULF8rPz0+tW7dWfHy89bVqIysrS5GRkWrZsqU8PDw0evRonT171rr/iy++0G9+8xu5u7vLw8NDffv21WeffSbp6m+UDRs2TN7e3nJzc1PPnj21efPmWvelKrWa87NgwQINHTpUKSkp1mf8pKWl6fTp0/XaWQBAE2MY0pWL9nnt5q6SxVJlmaOjo2JjY7V69Wo9++yzsvzfMevWrVNJSYmio6NVVFSkvn37avr06fLw8NCHH36ohx9+WJ07d67WN51LS0s1cuRI+fj4aN++fSooKCh3LpC7u7tWr14tf39/paen67HHHpO7u7umTZumBx98UEePHtWWLVuUkpIiSfL09CzTxoULFxQeHq7Q0FAdOHBA586d06OPPqqJEyfaBLydO3fKz89PO3fu1MmTJ/Xggw+qT58+euyxx6ocT3njuxZ8du3apZ9++knx8fF68MEHrfN3Y2JidOutt2rp0qVycHDQ4cOH1bx5c0lXf+rq8uXL+vjjj+Xm5qavvvpKLVu2rHE/qqtW4WfQoEH697//rVdffVVff/21JGnkyJEaP368nn/+eevvfgEATO7KRemv/vZ57WfOSC3cqq6T9Mgjj+jFF1/Url27dPfdd0u6estr1KhR8vT0lKenp6ZOnWqtnzRpkrZu3ar33nuvWuEnJSVFX3/9tbZu3Sp//6t/H3/961/LzNOZOXOm9c8dO3bU1KlTlZycrGnTpsnFxUUtW7aUo6OjfH19K3ytt99+W5cuXdKaNWusv325ZMkSDRs2TPPnz5ePj48kydvbW0uWLJGDg4OCg4M1dOhQ7dixo1bhZ8eOHUpPT1dmZqYCAgIkSWvWrFHPnj114MAB3X777crKytLTTz9tnTbTtWtX6/FZWVkaNWqUevXqJenqA4rrU62f8+Pv71/mW11ffPGFVqxYoddff/26OwYAQEMJDg7WgAEDtHLlSt199906efKkPvnkEz333HOSpJKSEv31r3/Ve++9p++++06XL19WcXFxtef0HDt2TAEBAdbgI8l65+Tn3n33XS1evFgZGRkqKirSTz/9VONfHTh27Jh69+5t86Pfd955p0pLS3X8+HFr+OnZs6fNA4X9/PzKPHy4Jq8ZEBBgDT6S1KNHD3l5eenYsWO6/fbb9ec//1mPPvqo/vGPfygsLEwPPPCAOnfuLEn64x//qAkTJmjbtm0KCwvTqFGj6nUaTa3DDwAAVWruevUKjL1euwbi4uI0adIkvfrqq1q1apU6d+6sQYMGSZJefPFF/f3vf9eiRYvUq1cvubm5acqUKbp8+XKddTctLU0xMTFKTExUeHi4PD09lZycrJdeeqnOXuPnrt1yusZisdTps/p+KSEhQb///e/14Ycf6qOPPtKcOXOUnJysESNG6NFHH1V4eLg+/PBDbdu2TUlJSXrppZc0adKkeulLrSY8AwBQLRbL1VtP9liqMd/n50aPHq1mzZrp7bff1po1a/TII49Y5//s3r1bkZGReuihh9S7d2916tRJ//73v6vddvfu3XX69GmbB/fu3bvXpmbPnj3q0KGDnn32WfXr109du3bVqVOnbGpatGhR6W9fXnutL774QhcuXLBu2717t5o1a6agoKBq97kmro3v5z8M/tVXXyk/P189evSwbuvWrZv+9Kc/adu2bRo5cqRWrVpl3RcQEKAnnnhC69ev11NPPaXly5fXS18lwg8AAJKkli1b6sEHH9SMGTOUk5OjcePGWfd17dpV27dv1549e3Ts2DE9/vjjNt9kqkpYWJi6deumsWPH6osvvtAnn3yiZ5991qama9euysrKUnJysjIyMrR48WJt2LDBpqZjx47KzMzU4cOH9Z///EfFxcVlXismJkbOzs4aO3asjh49qp07d2rSpEl6+OGHrbe8aqukpESHDx+2WY4dO6awsDD16tVLMTExOnjwoPbv36/Y2FgNGjRI/fr1048//qiJEycqNTVVp06d0u7du3XgwAF1795dkjRlyhRt3bpVmZmZOnjwoHbu3GndVx9qdNtr5MiRle7Pz8+/nr4AAGBXcXFxWrFihe677z6b+TkzZ87UN998o/DwcLm6umr8+PGKiopSQUFBtdpt1qyZNmzYoLi4ON1xxx3q2LGjFi9ebPNwxeHDh+tPf/qTJk6cqOLiYg0dOlSzZs1SQkKCtWbUqFFav369fvOb3yg/P1+rVq2yCWmS5Orqqq1bt2ry5Mm6/fbb5erqqlGjRunll1++rr8b6erX/2+99VabbZ07d9bJkyf1/vvva9KkSfr1r3+tZs2aKSIiQq+88oqkqz8/lZeXp9jYWJ09e1Zt2rTRyJEjlZiYKOlqqIqPj1d2drY8PDwUERGhv/3tb9fd34pYjIp+K6Icf/jDH6pV9/PLWE1RYWGhPD09VVBQUOOJZgBgVpcuXVJmZqYCAwPl7Oxs7+7gBlXZv7Pqfn7X6MpPUw81AAAAzPkBAACmQvgBAACmQvgBAACmQvgBANSpGnyPBqixuvj3RfgBANSJa08MvnjRTj9kClO49u/rl0+orgl+3gIAUCccHBzk5eWlc+fOSbr6vBlLDZ+yDFTEMAxdvHhR586dk5eXl83vktUU4QcAUGeu/dr4tQAE1DUvL69Kf9W+Ogg/AIA6Y7FY5Ofnp3bt2unKlSv27g5uMM2bN7+uKz7XEH4AAHXOwcGhTj6kgPrAhGcAAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqhB8AAGAqjSb8zJs3TxaLRVOmTKmwZvXq1bJYLDaLs7OzTY1hGJo9e7b8/Pzk4uKisLAwnThxop57DwAAmopGEX4OHDigZcuWKSQkpMpaDw8P5eTkWJdTp07Z7F+wYIEWL16s1157Tfv27ZObm5vCw8N16dKl+uo+AABoQuwefoqKihQTE6Ply5fL29u7ynqLxSJfX1/r4uPjY91nGIYWLVqkmTNnKjIyUiEhIVqzZo3OnDmjjRs31uMoAABAU2H38BMfH6+hQ4cqLCysWvVFRUXq0KGDAgICFBkZqS+//NK6LzMzU7m5uTZteXp6qn///kpLS6uwzeLiYhUWFtosAADgxmTX8JOcnKyDBw8qKSmpWvVBQUFauXKl3n//fb311lsqLS3VgAEDlJ2dLUnKzc2VJJurQdfWr+0rT1JSkjw9Pa1LQEBALUcEAAAaO7uFn9OnT2vy5Mlau3ZtmUnLFQkNDVVsbKz69OmjQYMGaf369Wrbtq2WLVt2XX2ZMWOGCgoKrMvp06evqz0AANB4OdrrhT///HOdO3dOt912m3VbSUmJPv74Yy1ZskTFxcVycHCotI3mzZvr1ltv1cmTJyVJvr6+kqSzZ8/Kz8/PWnf27Fn16dOnwnacnJzk5OR0HaMBAABNhd2u/AwePFjp6ek6fPiwdenXr59iYmJ0+PDhKoOPdDUspaenW4NOYGCgfH19tWPHDmtNYWGh9u3bp9DQ0HobCwAAaDrsduXH3d1dt9xyi802Nzc3tW7d2ro9NjZW7du3t84Jeu655/SrX/1KXbp0UX5+vl588UWdOnVKjz76qCRZnxP0/PPPq2vXrgoMDNSsWbPk7++vqKioBh0fAABonOwWfqojKytLzZr99+LUDz/8oMcee0y5ubny9vZW3759tWfPHvXo0cNaM23aNF24cEHjx49Xfn6+Bg4cqC1btlR7XhEAALixWQzDMOzdicamsLBQnp6eKigokIeHh727AwAAqqG6n992f84PAABAQyL8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAUyH8AAAAU2k04WfevHmyWCyaMmVKhTXLly/XXXfdJW9vb3l7eyssLEz79++3qRk3bpwsFovNEhERUc+9BwAATUWjCD8HDhzQsmXLFBISUmldamqqoqOjtXPnTqWlpSkgIED33nuvvvvuO5u6iIgI5eTkWJd33nmnPrsPAACaELuHn6KiIsXExGj58uXy9vautHbt2rV68skn1adPHwUHB+uNN95QaWmpduzYYVPn5OQkX19f61JVuwAAwDzsHn7i4+M1dOhQhYWF1fjYixcv6sqVK2rVqpXN9tTUVLVr105BQUGaMGGC8vLyKm2nuLhYhYWFNgsAALgxOdrzxZOTk3Xw4EEdOHCgVsdPnz5d/v7+NsEpIiJCI0eOVGBgoDIyMvTMM89oyJAhSktLk4ODQ7ntJCUlKTExsVZ9AAAATYvFMAzDHi98+vRp9evXT9u3b7fO9bn77rvVp08fLVq0qMrj582bpwULFig1NbXSuULffPONOnfurJSUFA0ePLjcmuLiYhUXF1vXCwsLFRAQoIKCAnl4eNRsYAAAwC4KCwvl6elZ5ee33W57ff755zp37pxuu+02OTo6ytHRUbt27dLixYvl6OiokpKSCo9duHCh5s2bp23btlU5SbpTp05q06aNTp48WWGNk5OTPDw8bBYAAHBjstttr8GDBys9Pd1m2x/+8AcFBwdr+vTpFd6iWrBggV544QVt3bpV/fr1q/J1srOzlZeXJz8/vzrpNwAAaNrsFn7c3d11yy232Gxzc3NT69atrdtjY2PVvn17JSUlSZLmz5+v2bNn6+2331bHjh2Vm5srSWrZsqVatmypoqIiJSYmatSoUfL19VVGRoamTZumLl26KDw8vGEHCAAAGiW7f9urMllZWcrJybGuL126VJcvX9b9998vPz8/67Jw4UJJkoODg44cOaLhw4erW7duiouLU9++ffXJJ5/IycnJXsMAAACNiN0mPDdm1Z0wBQAAGo9GP+EZAADAHgg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVAg/AADAVBpN+Jk3b54sFoumTJlSad26desUHBwsZ2dn9erVS5s3b7bZbxiGZs+eLT8/P7m4uCgsLEwnTpyox54DAICmpFGEnwMHDmjZsmUKCQmptG7Pnj2Kjo5WXFycDh06pKioKEVFReno0aPWmgULFmjx4sV67bXXtG/fPrm5uSk8PFyXLl2q72EAAIAmwO7hp6ioSDExMVq+fLm8vb0rrf373/+uiIgIPf300+revbvmzp2r2267TUuWLJF09arPokWLNHPmTEVGRiokJERr1qzRmTNntHHjxgYYDQAAaOzsHn7i4+M1dOhQhYWFVVmblpZWpi48PFxpaWmSpMzMTOXm5trUeHp6qn///taa8hQXF6uwsNBmAQAANyZHe754cnKyDh48qAMHDlSrPjc3Vz4+PjbbfHx8lJuba91/bVtFNeVJSkpSYmJiTboOAACaKLtd+Tl9+rQmT56stWvXytnZ2V7dkCTNmDFDBQUF1uX06dN27Q8AAKg/drvy8/nnn+vcuXO67bbbrNtKSkr08ccfa8mSJSouLpaDg4PNMb6+vjp79qzNtrNnz8rX19e6/9o2Pz8/m5o+ffpU2BcnJyc5OTld75AAAEATYLcrP4MHD1Z6eroOHz5sXfr166eYmBgdPny4TPCRpNDQUO3YscNm2/bt2xUaGipJCgwMlK+vr01NYWGh9u3bZ60BAADmZrcrP+7u7rrllltstrm5ual169bW7bGxsWrfvr2SkpIkSZMnT9agQYP00ksvaejQoUpOTtZnn32m119/XZKszwl6/vnn1bVrVwUGBmrWrFny9/dXVFRUg44PAAA0Tnad8FyVrKwsNWv234tTAwYM0Ntvv62ZM2fqmWeeUdeuXbVx40abEDVt2jRduHBB48ePV35+vgYOHKgtW7bYfV4RAABoHCyGYRj27kRjU1hYKE9PTxUUFMjDw8Pe3QEAANVQ3c9vuz/nBwAAoCERfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKkQfgAAgKk42rsDprJrgfTlBsnRSXJwkhxbSI7OksP//dfR6fr3OThKslTeD0sV+6s6vt4YdnpdAECDc2klOXvY5aUJPw2p4LR07it79wIAAPv73SKp3x/s8tKEn4Y04I/SLaOkn4r/u5RU8Gfr+iXpp8tX/1ty+b/rFdWW/FRFJyq5umJUdeXFUI2vClV5lQkAYErN7BdBCD8NqU3XqwsAALAbJjwDAABTIfwAAABTIfwAAABTIfwAAABTIfwAAABTIfwAAABTsWv4Wbp0qUJCQuTh4SEPDw+Fhobqo48+qrD+7rvvlsViKbMMHTrUWjNu3Lgy+yMiIhpiOAAAoAmw63N+brrpJs2bN09du3aVYRh68803FRkZqUOHDqlnz55l6tevX6/Lly9b1/Py8tS7d2898MADNnURERFatWqVdd3Jyan+BgEAAJoUu4afYcOG2ay/8MILWrp0qfbu3Vtu+GnVqpXNenJyslxdXcuEHycnJ/n6+tZ9hwEAQJPXaOb8lJSUKDk5WRcuXFBoaGi1jlmxYoXGjBkjNzc3m+2pqalq166dgoKCNGHCBOXl5VXaTnFxsQoLC20WAABwY7L7z1ukp6crNDRUly5dUsuWLbVhwwb16NGjyuP279+vo0ePasWKFTbbIyIiNHLkSAUGBiojI0PPPPOMhgwZorS0NDk4OJTbVlJSkhITE+tkPAAAoHGzGEaVv2ZZry5fvqysrCwVFBTon//8p9544w3t2rWrygD0+OOPKy0tTUeOHKm07ptvvlHnzp2VkpKiwYMHl1tTXFys4uJi63phYaECAgJUUFAgDw+Pmg8KAAA0uMLCQnl6elb5+W33214tWrRQly5d1LdvXyUlJal37976+9//XukxFy5cUHJysuLi4qpsv1OnTmrTpo1OnjxZYY2Tk5P1G2fXFgAAcGOye/j5pdLSUpurMOVZt26diouL9dBDD1XZXnZ2tvLy8uTn51dXXQQAAE2YXef8zJgxQ0OGDNHNN9+s8+fP6+2331Zqaqq2bt0qSYqNjVX79u2VlJRkc9yKFSsUFRWl1q1b22wvKipSYmKiRo0aJV9fX2VkZGjatGnq0qWLwsPDq92va3cCmfgMAEDTce1zu6oZPXYNP+fOnVNsbKxycnLk6empkJAQbd26Vb/97W8lSVlZWWrWzPbi1PHjx/Xpp59q27ZtZdpzcHDQkSNH9Oabbyo/P1/+/v669957NXfu3Bo96+f8+fOSpICAgOsYHQAAsIfz58/L09Ozwv12n/DcGJWWlurMmTNyd3eXxWKxd3fqzbWJ3adPn77h5zmZaaySucbLWG9cZhovY60bhmHo/Pnz8vf3L3Px5Ofs/lX3xqhZs2a66aab7N2NBmOmSd5mGqtkrvEy1huXmcbLWK9fZVd8rml0E54BAADqE+EHAACYCuHHxJycnDRnzhxT/PCrmcYqmWu8jPXGZabxMtaGxYRnAABgKlz5AQAApkL4AQAApkL4AQAApkL4AQAApkL4uUElJSXp9ttvl7u7u9q1a6eoqCgdP3680mNWr14ti8Viszg7OzdQj69PQkJCmb4HBwdXesy6desUHBwsZ2dn9erVS5s3b26g3l6fjh07lhmrxWJRfHx8ufVN6bx+/PHHGjZsmPz9/WWxWLRx40ab/YZhaPbs2fLz85OLi4vCwsJ04sSJKtt99dVX1bFjRzk7O6t///7av39/PY2gZiob75UrVzR9+nT16tVLbm5u8vf3V2xsrM6cOVNpm7V5LzSEqs7tuHHjyvQ7IiKiynYb47mtaqzlvX8tFotefPHFCttsrOe1Op81ly5dUnx8vFq3bq2WLVtq1KhROnv2bKXt1va9Xl2EnxvUrl27FB8fr71792r79u26cuWK7r33Xl24cKHS4zw8PJSTk2NdTp061UA9vn49e/a06funn35aYe2ePXsUHR2tuLg4HTp0SFFRUYqKitLRo0cbsMe1c+DAAZtxbt++XZL0wAMPVHhMUzmvFy5cUO/evfXqq6+Wu3/BggVavHixXnvtNe3bt09ubm4KDw/XpUuXKmzz3Xff1Z///GfNmTNHBw8eVO/evRUeHq5z587V1zCqrbLxXrx4UQcPHtSsWbN08OBBrV+/XsePH9fw4cOrbLcm74WGUtW5laSIiAibfr/zzjuVttlYz21VY/35GHNycrRy5UpZLBaNGjWq0nYb43mtzmfNn/70J/3v//6v1q1bp127dunMmTMaOXJkpe3W5r1eIwZM4dy5c4YkY9euXRXWrFq1yvD09Gy4TtWhOXPmGL179652/ejRo42hQ4fabOvfv7/x+OOP13HP6t/kyZONzp07G6WlpeXub6rnVZKxYcMG63ppaanh6+trvPjii9Zt+fn5hpOTk/HOO+9U2M4dd9xhxMfHW9dLSkoMf39/IykpqV76XVu/HG959u/fb0gyTp06VWFNTd8L9lDeWMeOHWtERkbWqJ2mcG6rc14jIyONe+65p9KapnBeDaPsZ01+fr7RvHlzY926ddaaY8eOGZKMtLS0ctuo7Xu9JrjyYxIFBQWSpFatWlVaV1RUpA4dOiggIECRkZH68ssvG6J7deLEiRPy9/dXp06dFBMTo6ysrApr09LSFBYWZrMtPDxcaWlp9d3NOnX58mW99dZbeuSRRyr9Ed6mfF6vyczMVG5urs158/T0VP/+/Ss8b5cvX9bnn39uc0yzZs0UFhbW5M61dPV9bLFY5OXlVWldTd4LjUlqaqratWunoKAgTZgwQXl5eRXW3ijn9uzZs/rwww8VFxdXZW1TOK+//Kz5/PPPdeXKFZvzFBwcrJtvvrnC81Sb93pNEX5MoLS0VFOmTNGdd96pW265pcK6oKAgrVy5Uu+//77eeustlZaWasCAAcrOzm7A3tZO//79tXr1am3ZskVLly5VZmam7rrrLp0/f77c+tzcXPn4+Nhs8/HxUW5ubkN0t85s3LhR+fn5GjduXIU1Tfm8/ty1c1OT8/af//xHJSUlN8S5vnTpkqZPn67o6OhKfwyypu+FxiIiIkJr1qzRjh07NH/+fO3atUtDhgxRSUlJufU3yrl988035e7uXuVtoKZwXsv7rMnNzVWLFi3KBPbKzlNt3us1xa+6m0B8fLyOHj1a5f3h0NBQhYaGWtcHDBig7t27a9myZZo7d259d/O6DBkyxPrnkJAQ9e/fXx06dNB7771Xrf+jaqpWrFihIUOGyN/fv8KapnxecdWVK1c0evRoGYahpUuXVlrbVN8LY8aMsf65V69eCgkJUefOnZWamqrBgwfbsWf1a+XKlYqJianySwhN4bxW97OmMeDKzw1u4sSJ+uCDD7Rz507ddNNNNTq2efPmuvXWW3Xy5Ml66l398fLyUrdu3Srsu6+vb5lvG5w9e1a+vr4N0b06cerUKaWkpOjRRx+t0XFN9bxeOzc1OW9t2rSRg4NDkz7X14LPqVOntH379kqv+pSnqvdCY9WpUye1adOmwn7fCOf2k08+0fHjx2v8HpYa33mt6LPG19dXly9fVn5+vk19ZeepNu/1miL83KAMw9DEiRO1YcMG/etf/1JgYGCN2ygpKVF6err8/PzqoYf1q6ioSBkZGRX2PTQ0VDt27LDZtn37dpsrJI3dqlWr1K5dOw0dOrRGxzXV8xoYGChfX1+b81ZYWKh9+/ZVeN5atGihvn372hxTWlqqHTt2NIlzfS34nDhxQikpKWrdunWN26jqvdBYZWdnKy8vr8J+N/VzK129ctu3b1/17t27xsc2lvNa1WdN37591bx5c5vzdPz4cWVlZVV4nmrzXq9Nx3EDmjBhguHp6WmkpqYaOTk51uXixYvWmocfftj4y1/+Yl1PTEw0tm7damRkZBiff/65MWbMGMPZ2dn48ssv7TGEGnnqqaeM1NRUIzMz09i9e7cRFhZmtGnTxjh37pxhGGXHunv3bsPR0dFYuHChcezYMWPOnDlG8+bNjfT0dHsNoUZKSkqMm2++2Zg+fXqZfU35vJ4/f944dOiQcejQIUOS8fLLLxuHDh2yfrtp3rx5hpeXl/H+++8bR44cMSIjI43AwEDjxx9/tLZxzz33GK+88op1PTk52XBycjJWr15tfPXVV8b48eMNLy8vIzc3t8HH90uVjffy5cvG8OHDjZtuusk4fPiwzfu4uLjY2sYvx1vVe8FeKhvr+fPnjalTpxppaWlGZmamkZKSYtx2221G165djUuXLlnbaCrntqp/x4ZhGAUFBYarq6uxdOnScttoKue1Op81TzzxhHHzzTcb//rXv4zPPvvMCA0NNUJDQ23aCQoKMtavX29dr857/XoQfm5QkspdVq1aZa0ZNGiQMXbsWOv6lClTjJtvvtlo0aKF4ePjY9x3333GwYMHG77ztfDggw8afn5+RosWLYz27dsbDz74oHHy5Enr/l+O1TAM47333jO6detmtGjRwujZs6fx4YcfNnCva2/r1q2GJOP48eNl9jXl87pz585y/91eG09paakxa9Ysw8fHx3BycjIGDx5c5u+gQ4cOxpw5c2y2vfLKK9a/gzvuuMPYu3dvA42ocpWNNzMzs8L38c6dO61t/HK8Vb0X7KWysV68eNG49957jbZt2xrNmzc3OnToYDz22GNlQkxTObdV/Ts2DMNYtmyZ4eLiYuTn55fbRlM5r9X5rPnxxx+NJ5980vD29jZcXV2NESNGGDk5OWXa+fkx1XmvXw/L/70oAACAKTDnBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwAAmArhBwCqwWKxaOPGjfbuBoA6QPgB0OiNGzdOFoulzBIREWHvrgFoghzt3QEAqI6IiAitWrXKZpuTk5OdegOgKePKD4AmwcnJSb6+vjaLt7e3pKu3pJYuXaohQ4bIxcVFnTp10j//+U+b49PT03XPPffIxcVFrVu31vjx41VUVGRTs3LlSvXs2VNOTk7y8/PTxIkTbfb/5z//0YgRI+Tq6qquXbtq06ZN9TtoAPWC8APghjBr1iyNGjVKX3zxhWJiYjRmzBgdO3ZMknThwgWFh4fL29tbBw4c0Lp165SSkmITbpYuXar4+HiNHz9e6enp2rRpk7p06WLzGomJiRo9erSOHDmi++67TzExMfr+++8bdJwA6kCd/UQqANSTsWPHGg4ODoabm5vN8sILLxiGcfUXoZ944gmbY/r3729MmDDBMAzDeP311w1vb2+jqKjIuv/DDz80mjVrZv3lcH9/f+PZZ5+tsA+SjJkzZ1rXi4qKDEnGRx99VGfjBNAwmPMDoEn4zW9+o6VLl9psa9WqlfXPoaGhNvtCQ0N1+PBhSdKxY8fUu3dvubm5WfffeeedKi0t1fHjx2WxWHTmzBkNHjy40j6EhIRY/+zm5iYPDw+dO3eutkMCYCeEHwBNgpubW5nbUHXFxcWlWnXNmze3WbdYLCotLa2PLgGoR8z5AXBD2Lt3b5n17t27S5K6d++uL774QhcuXLDu3717t5o1a6agoCC5u7urY8eO2rFjR4P2GYB9cOUHQJNQXFys3Nxcm22Ojo5q06aNJGndunXq16+fBg4cqLVr12r//v1asWKFJCkmJkZz5szR2LFjlZCQoP/3//6fJk2apIcfflg+Pj6SpISEBD3xxBNq166dhgwZovPnz2v37t2aNGlSww4UQL0j/ABoErZs2SI/Pz+bbUFBQfr6668lXf0mVnJysp588kn5+fnpnXfeUY8ePSRJrq6u2rp1qyZPnqzbb79drq6uGjVqlF5++WVrW2PHjtWlS5f0t7/9TVOnTlWbNm10//33N9wAATQYi2EYhr07AQDXw2KxaMOGDYqKirJ3VwA0Acz5AQAApkL4AQAApsKcHwBNHnfvAdQEV34AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICpEH4AAICp/H8Zhys2CEDWPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_model = True\n",
    "\n",
    "# Training hyperparameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model hyperparameters\n",
    "print(\"Length english vocabulary:\", len(vocab_en))\n",
    "print(\"Length spanish vocabulary:\",len(vocab_es))\n",
    "input_size_encoder = len(vocab_en)\n",
    "input_size_decoder = len(vocab_es)\n",
    "output_size = len(vocab_es)\n",
    "encoder_embedding_size = 256\n",
    "decoder_embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "step = 0\n",
    "\n",
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        #for _text,_label in batch:\n",
    "        english_text, spanish_text = batch\n",
    "        #print('target shape:',spanish_text.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(english_text, spanish_text,len(vocab_es))\n",
    "        flat_target = spanish_text.view(-1)\n",
    "        loss = criterion(output.view(-1, len(vocab_es)), flat_target)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1) #gradient clipping\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            english_text, spanish_text = batch\n",
    "            output = model(english_text, spanish_text, len(vocab_es))\n",
    "            flat_target = spanish_text.view(-1)\n",
    "            loss = criterion(output.view(-1, len(vocab_es)), flat_target)\n",
    "            total_validation_loss += loss.item()\n",
    "    \n",
    "    average_validation_loss = total_validation_loss / len(valid_loader)\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}, Validation Loss: {average_validation_loss}')\n",
    "    train_losses.append(loss.item())\n",
    "    validation_losses.append(average_validation_loss)\n",
    "\n",
    "\n",
    "print('ENTRENAMIENTO FINALIZADO')\n",
    "\n",
    "# Plotting\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7e1bc6-c6c6-40b4-bced-b286c279c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH INPUT TEXT:  torch.Size([2, 300])\n",
      "build a sandcastle on the beach\n",
      "find shapes in fluffy clouds\n",
      "\n",
      "SPANISH INPUT TEXT:  torch.Size([2, 300])\n",
      "construye un castillo de arena en la playa\n",
      "encuentra formas en las nubes esponjosas\n",
      "\n",
      "PREDICTED TEXT:  torch.Size([2, 300])\n",
      "\n",
      "mundo impresionantes todos disfrutar aire\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create reverse vocabularies\n",
    "reverse_vocab_en = {index: word for word, index in vocab_en.get_stoi().items()}\n",
    "reverse_vocab_es = {index: word for word, index in vocab_es.get_stoi().items()}\n",
    "\n",
    "\n",
    "# Testing (optional)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        english_text, spanish_text = batch\n",
    "        output = model(english_text, spanish_text,len(vocab_es))\n",
    "        log_probs = F.log_softmax(output, dim=2)\n",
    "        predicted_indices = log_probs.argmax(dim=2)\n",
    "        \n",
    "        print('ENGLISH INPUT TEXT: ',english_text.shape)\n",
    "        sentence = untokenize_batch(english_text,reverse_vocab_en)\n",
    "        print(''.join([' '.join(s) + '\\n' for s in sentence]))\n",
    "\n",
    "        print('SPANISH INPUT TEXT: ',spanish_text.shape)\n",
    "        sentence = untokenize_batch(spanish_text,reverse_vocab_es)\n",
    "        print(''.join([' '.join(s) + '\\n' for s in sentence]))\n",
    "\n",
    "        print('PREDICTED TEXT: ',predicted_indices.shape)\n",
    "        sentence = untokenize_batch(predicted_indices,reverse_vocab_es)\n",
    "        print(''.join([' '.join(s) + '\\n' for s in sentence]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb826f82-abb7-4ef2-8a76-c7e3531390fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 1, 0, 2, 0, 2, 2, 3, 2, 2, 0, 0, 3, 2])\n",
      "tensor([2, 2, 2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "#target shape: torch.Size([3, 300])\n",
    "#predicted_indices shape: torch.Size([3, 300, 124])\n",
    "\n",
    "batch_size = 3\n",
    "sequence_size = 5\n",
    "vocabulary_size = 4\n",
    "\n",
    "spanish_text = torch.randint(0, vocabulary_size, (batch_size, sequence_size))\n",
    "#print('target shape:',spanish_text.shape)\n",
    "#print(spanish_text)\n",
    "output = torch.randn((batch_size, sequence_size, vocabulary_size))  # Random values for demonstration\n",
    "#print('\\n output shape:', output.shape)\n",
    "#print(output)\n",
    "\n",
    "log_probs = F.log_softmax(output, dim=2)\n",
    "predicted_indices = log_probs.argmax(dim=2)\n",
    "#print('\\nLog Probabilities (after log softmax):\\n', log_probs)\n",
    "#print('\\nPredicted Indices (argmax):\\n', predicted_indices)\n",
    "\n",
    "flat_predicted_indices = predicted_indices.view(-1)\n",
    "print(flat_predicted_indices)\n",
    "flat_target = spanish_text.view(-1)\n",
    "print(flat_target)\n",
    "\n",
    "loss = criterion(output.view(-1, vocabulary_size), flat_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40783e-0afc-4fea-983c-21cd356b8f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
