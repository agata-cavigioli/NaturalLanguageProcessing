{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f283ed4-3b74-4b8a-8d4e-5593445a9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'simple', 'example', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def simple_tokenizer(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Example usage:\n",
    "text_example = \"This is a, simple example sentence.\"\n",
    "tokens_example = simple_tokenizer(text_example)\n",
    "print(tokens_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95908a5b-58b1-4d5b-9f7d-9ff456d460d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import string\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "allowed_chars = string.ascii_lowercase + ' '\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, file_en, file_es,max_length):\n",
    "        self.sentences_en = self.load_sentences(file_en)\n",
    "        self.sentences_es = self.load_sentences(file_es)\n",
    "\n",
    "        self.tokenizer_es = self.tokenizer\n",
    "        self.tokenizer_en = self.tokenizer\n",
    "\n",
    "        self.vocab_en = self.build_vocab(self.sentences_en)\n",
    "        self.vocab_es = self.build_vocab(self.sentences_es)\n",
    "\n",
    "        self.archivo_ingles = file_en\n",
    "        self.archivo_espanol = file_es\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def build_vocab(self, sentences):\n",
    "        words = set()\n",
    "        for sentence in sentences:\n",
    "            words.update(self.tokenizer(sentence))\n",
    "        vocab = {word: idx for idx, word in enumerate(words)}\n",
    "        return vocab\n",
    "\n",
    "    def load_sentences(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return [line.strip() for line in file]\n",
    "\n",
    "    def sample(self):\n",
    "        index = random.randint(0, len(self.sentences_en) - 1)\n",
    "        ## Input Size [batch_size, max_source_sequence_length, 300]\n",
    "        # Output Size [batch_size, max_target_sequence_length, 512]\n",
    "        return self.string_to_tensor(self.sentences_en[index],self.vocab_en), self.string_to_tensor(self.sentences_es[index],self.vocab_es)\n",
    "\n",
    "    def batch_to_tensor(self, n):\n",
    "        seq_in = []\n",
    "        seq_out = []\n",
    "        inputs, outputs = self.batch(n)\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            seq_in.append(self.string_to_tensor(input, self.vocab_en))\n",
    "            seq_out.append(self.string_to_tensor(output, self.vocab_es))\n",
    "        return pad_sequence(seq_in, batch_first=True), pad_sequence(seq_out, batch_first=True)\n",
    "        \n",
    "    def batch(self, n):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for _ in range(n):\n",
    "            input, output = self.sample()\n",
    "            inputs.append(input)\n",
    "            outputs.append(output)\n",
    "        # Convert the lists of tensors to a single tensor along the batch dimension\n",
    "        #input_tensor = torch.stack(inputs, dim=0)\n",
    "        #output_tensor = torch.stack(outputs, dim=0)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def string_to_tensor(self, s, vocab):\n",
    "        indices = [vocab.get(token, len(vocab) - 1) for token in self.tokenizer(s)] + [vocab.get('<pad>', len(vocab) - 1)]\n",
    "        # Ensure the tensor has a fixed length by padding or truncating\n",
    "        indices = indices[:self.max_length] + [0] * max(0, self.max_length - len(indices))\n",
    "        res = torch.tensor(indices)\n",
    "        return res\n",
    "\n",
    "    def tokens_to_tensor(self, tokens, vocab):\n",
    "        return torch.stack([torch.tensor(vocab.get(token, len(vocab)-1)) for token in tokens])\n",
    "\n",
    "    def tensor_to_string(self, tensor, vocab, is_tensor=False): #############################################\n",
    "        if is_tensor:\n",
    "            indices = tensor.view(-1).tolist()\n",
    "        else:\n",
    "            indices = tensor\n",
    "        return ''.join([list(vocab.keys())[int(idx)] for idx in indices])\n",
    "  \n",
    "    def tokens_to_indices(self, tokens, vocab):\n",
    "        return [vocab.stoi[token] for token in tokens] + [vocab.stoi['<pad>']]\n",
    "\n",
    "    def get_output_lengths(self, n):\n",
    "        _, outputs = self.batch(n)\n",
    "        return [len(seq) for seq in outputs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_en)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.sentences_en[idx], self.sentences_es[idx]\n",
    "        tokens_ingles = self.tokenizer_en(item[0])\n",
    "        tokens_espanol = self.tokenizer_es(item[1])\n",
    "\n",
    "        tokens_ingles = tokens_ingles + ['<eos>']\n",
    "        tokens_espanol = ['<sos>'] + tokens_espanol + ['<eos>']\n",
    "\n",
    "        if not tokens_ingles or not tokens_espanol:\n",
    "            return torch.zeros(1, len(self.vocab_en)), torch.zeros(1, len(self.vocab_es))\n",
    "    \n",
    "        tensor_ingles = self.string_to_tensor(item[0], self.vocab_en)\n",
    "        tensor_espanol = self.string_to_tensor(item[1], self.vocab_es)\n",
    "\n",
    "        indices_ingles = [self.vocab_en.get(token, len(self.vocab_en)-1) for token in tokens_ingles] + [self.vocab_en.get('<pad>', len(self.vocab_en)-1)]\n",
    "        indices_espanol = [self.vocab_es.get(token, len(self.vocab_es)-1) for token in tokens_espanol] + [self.vocab_es.get('<pad>', len(self.vocab_es)-1)]\n",
    "\n",
    "        return tensor_ingles, tensor_espanol\n",
    "\n",
    "    def tokenizer(self, text):\n",
    "        # Remove punctuation\n",
    "        if isinstance(text, torch.Tensor):\n",
    "            # Convert tensor to string\n",
    "            text = self.tensor_to_string(text, self.vocab_en)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = text.lower().split()\n",
    "        return tokens\n",
    "        \n",
    "    def add_sos_eos_unk_pad(self, vocabulary):\n",
    "        words = vocabulary.itos\n",
    "        vocab = vocabulary.stoi\n",
    "        embedding_matrix = vocabulary.vectors\n",
    "\n",
    "        # Tokens especiales\n",
    "        sos_token = '<sos>'\n",
    "        eos_token = '<eos>'\n",
    "        pad_token = '<pad>'\n",
    "        unk_token = '<unk>'\n",
    "\n",
    "        # Inicializamos los vectores para los tokens especiales, por ejemplo, con ceros\n",
    "        sos_vector = torch.full((1, embedding_matrix.shape[1]), 1.)\n",
    "        eos_vector = torch.full((1, embedding_matrix.shape[1]), 2.)\n",
    "        pad_vector = torch.zeros((1, embedding_matrix.shape[1]))\n",
    "        unk_vector = torch.full((1, embedding_matrix.shape[1]), 3.)\n",
    "\n",
    "        # Añade los vectores al final de la matriz de embeddings\n",
    "        embedding_matrix = torch.cat((embedding_matrix, sos_vector, eos_vector, unk_vector, pad_vector), 0)\n",
    "\n",
    "        # Añade los tokens especiales al vocabulario\n",
    "        vocab[sos_token] = len(vocab)\n",
    "        vocab[eos_token] = len(vocab)\n",
    "        vocab[pad_token] = len(vocab)\n",
    "        vocab[unk_token] = len(vocab)\n",
    "\n",
    "        words.append(sos_token)\n",
    "        words.append(eos_token)\n",
    "        words.append(pad_token)\n",
    "        words.append(unk_token)\n",
    "\n",
    "        vocabulary.itos = words\n",
    "        vocabulary.stoi = vocab\n",
    "        vocabulary.vectors = embedding_matrix\n",
    "\n",
    "        default_stoi = defaultdict(lambda : len(vocabulary)-1, vocabulary.stoi)\n",
    "        vocabulary.stoi = default_stoi\n",
    "        return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b14222c-44a0-401f-be7a-7d3f925b0aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "###### CARGAMENTO #####\n",
      "torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "###### INICIALIZACION MODELO #####\n",
      "300\n",
      "###### ENTRENAMIENTO #####\n",
      "torch.Size([8, 10])\n",
      "torch.Size([8, 10])\n",
      "---\n",
      "torch.Size([8, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 300, got 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 163\u001b[0m\n\u001b[1;32m    161\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m###### ENTRENAMIENTO #####\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 133\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, n_epochs, batch_size, train_loader)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m## Input Size [batch_size, max_source_sequence_length, 300]\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Output Size [batch_size, max_target_sequence_length, 512]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(padded_tensor1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 133\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_tensor1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqesto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 80\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     77\u001b[0m encoder_hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m     78\u001b[0m encoder_cell \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m---> 80\u001b[0m output_enc, (hn_enc, cn_enc) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_cell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m.\u001b[39massign_encoder_hidden_states(output_enc)\n\u001b[1;32m     83\u001b[0m latent_tensor \u001b[38;5;241m=\u001b[39m output_enc\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m---> 23\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, (hidden, cell)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:875\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    872\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:790\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    786\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    787\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    788\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    789\u001b[0m                        ):\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    792\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    794\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:236\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 300, got 10"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ingles_batch, espanol_batch= zip(*batch)\n",
    "    ingles_batch = pad_sequence(ingles_batch, batch_first=True, padding_value=0)\n",
    "    espanol_batch = pad_sequence(espanol_batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return ingles_batch, espanol_batch \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        print(input_dim)\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.rnn(x, hidden)\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.encoder_hidden_states = None\n",
    "\n",
    "    def assign_encoder_hidden_states(self, hidden_states):\n",
    "        self.encoder_hidden_states = hidden_states\n",
    "\n",
    "    def calculate_score(self, decoder_hidden_states):\n",
    "        print('-')\n",
    "        print(decoder_hidden_states.shape)\n",
    "        print(self.encoder_hidden_states.shape)\n",
    "        self.encoder_hidden_states = self.encoder_hidden_states.unsqueeze(1).repeat(1, decoder_hidden_states.shape[1], 1)\n",
    "        print(self.encoder_hidden_states.transpose(1, 2).shape)\n",
    "        return torch.bmm(decoder_hidden_states, self.encoder_hidden_states.transpose(1, 2))\n",
    "\n",
    "        #decoder_hidden_states has shape (batch_size, seq_len, hidden_size) and \n",
    "        #self.encoder_hidden_states has shape (batch_size, hidden_size, seq_len)\n",
    "        \n",
    "    def source_context(self, decoder_hidden_states):\n",
    "        energy = self.calculate_score(decoder_hidden_states)\n",
    "        attention_weights = F.softmax(energy, dim=-1)\n",
    "        context_vector = torch.bmm(attention_weights, self.encoder_hidden_states)\n",
    "\n",
    "        return context_vector #attention_weights, context_vector\n",
    "\n",
    "    def forward(self, decoder_hidden_state):\n",
    "        return self.source_context(decoder_hidden_state)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.rnn(x, (hidden, cell))\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.attention = LuongAttention()\n",
    "        self.decoder = Decoder(hidden_size, hidden_size)\n",
    "        self.reduce_dimension = nn.Linear(hidden_size, output_size)\n",
    "        self.output = nn.Linear(output_size, output_size)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def forward(self, input, hidden=None):\n",
    "        batch_size = input.size(0)\n",
    "        encoder_hidden = torch.zeros(1, self.encoder.rnn.hidden_size)\n",
    "        encoder_cell = torch.zeros(1, self.encoder.rnn.hidden_size)\n",
    "\n",
    "        output_enc, (hn_enc, cn_enc) = self.encoder(input, (encoder_hidden, encoder_cell))\n",
    "        self.attention.assign_encoder_hidden_states(output_enc)\n",
    "        \n",
    "        latent_tensor = output_enc.unsqueeze(1).repeat(1, input.size(1), 1)\n",
    "        \n",
    "        hn_enc = hn_enc.unsqueeze(1).repeat(1, batch_size, 1)\n",
    "        cn_enc = cn_enc.unsqueeze(1).repeat(1, batch_size, 1)\n",
    "        out_dec, (_, _) = self.decoder(latent_tensor, hn_enc, cn_enc)\n",
    "        print(5)\n",
    "        attention_output = self.attention(out_dec)\n",
    "\n",
    "        reduced_output = self.reduce_dimension(out_dec)\n",
    "        attention_output = attention_output[:, :, :reduced_output.size(2)]\n",
    "        return self.output(reduced_output * attention_output)\n",
    "\n",
    "archivo_ingles = 'mock.en'\n",
    "archivo_espanol = 'mock.es'\n",
    "max_length = 10  # Define your desired sequence length\n",
    "translator = Translator('mock.en', 'mock.es',max_length)\n",
    "\n",
    "# Parámetros\n",
    "input_dim = 300\n",
    "output_dim = translator.get_output_lengths(n=1)[0]\n",
    "print(output_dim)\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shuffle = True\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model, optimizer, loss_fn, n_epochs, batch_size, train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y= batch  \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('---')\n",
    "            # Determine the maximum sequence length\n",
    "            max_length = max(x.size(1), y.size(1))\n",
    "\n",
    "            padded_tensor1 = F.pad(x, (0, 0,max_length - x.size(1), 0))\n",
    "            padded_tensor2 = F.pad(y, (0, 0,max_length - y.size(1), 0))\n",
    "\n",
    "            ## Input Size [batch_size, max_source_sequence_length, 300]\n",
    "            # Output Size [batch_size, max_target_sequence_length, 512]\n",
    "            print(padded_tensor1.shape)\n",
    "            y_pred = model(padded_tensor1.float())\n",
    "            \n",
    "            print('qesto')\n",
    "            print(y_pred.shape)\n",
    "            print(y.shape)\n",
    "            loss = loss_fn(y_pred, padded_tensor2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss))\n",
    "        history.append(total_loss)\n",
    "\n",
    "print('###### CARGAMENTO #####')\n",
    "\n",
    "train_dataset = Translator('mock.en', 'mock.es',max_length)\n",
    "eval_dataset = Translator('mockeval.en', 'mockeval.es',max_length)\n",
    "\n",
    "padded_inputs, padded_outputs = train_dataset.batch_to_tensor(5)\n",
    "print(padded_inputs.shape)\n",
    "print(padded_outputs.shape)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "print('###### INICIALIZACION MODELO #####')\n",
    "model = Seq2Seq(input_dim, hidden_size, output_dim)\n",
    "history = []\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "print('###### ENTRENAMIENTO #####')\n",
    "train(model, optimizer, loss_fn, num_epochs, batch_size, train_loader)\n",
    "plt.plot(history, label='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfde69-951b-4b8d-a968-f0f2ef4f7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, n, eval_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            x, y= batch  # The collate_fn returns four elements, but we only need x and y for evaluation\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            for i in range(min(n, len(x))):\n",
    "            #    print(\"Predicted:\", translation.tensor_to_string(y_pred[i],translation.vocab_es))\n",
    "            #    print(\"Actual:\", translation.tensor_to_string(y[i],translation.vocab_es))\n",
    "            #    print()\n",
    "                #print(\"Predicted:\", y_pred[i])\n",
    "                #print(\"Actual:\", translator.tensor_to_string(y[i],translator.vocab_es))\n",
    "                predicted_word = translator.tensor_to_string(y_pred, translation.vocab_es, is_tensor=True)\n",
    "                print(\"Predicted word:\", predicted_word)\n",
    "evaluate(model, 5, eval_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90ee52-a9cf-46a3-ba20-c939ab88a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_enc = torch.rand(1, 512)\n",
    "print(hn_enc.shape)\n",
    "#hn_enc = torch.rand(batch_size, seq_len, hidden_size)\n",
    "latent_tensor = hn_enc.unsqueeze(1).repeat(1, input_dim, 1)\n",
    "hn_enc = hn_enc.unsqueeze(1).repeat(1, batch_size, 1)\n",
    "print(hn_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00a072-3644-4aa7-8170-726e79512d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
