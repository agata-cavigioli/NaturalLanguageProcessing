{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23f61ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "--------------------------------------------------\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "--------------------------------------------------\n",
      " \n",
      "\n",
      "--------------------------------------------------\n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \n",
      "\n",
      "--------------------------------------------------\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      "--------------------------------------------------\n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n",
      "--------------------------------------------------\n",
      " \n",
      "\n",
      "--------------------------------------------------\n",
      " = = Gameplay = = \n",
      "\n",
      "--------------------------------------------------\n",
      " \n",
      "\n",
      "--------------------------------------------------\n",
      " As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      " ###############MAP STYLE################# \n",
      "\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      " = = Original design = = \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agata/.local/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# Read the 10 first lines of WikiText2 dataset in TorchText\n",
    "import torch\n",
    "from torchtext import datasets\n",
    "\n",
    "# Load the dataset\n",
    "train_iter = datasets.WikiText2(split=('train'))\n",
    "\n",
    "# Print the first 10 lines\n",
    "for i, line in enumerate(train_iter):\n",
    "    if i < 10:\n",
    "        print(line)\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# print(train_iter[100])  # Error because the dataset is not a map-style dataset\n",
    "\n",
    "# Convert the dataset to map-style dataset\n",
    "from torchtext.data import to_map_style_dataset\n",
    "\n",
    "train_iter = to_map_style_dataset(train_iter)\n",
    "print('\\n ###############MAP STYLE################# \\n')\n",
    "print(train_iter[4])\n",
    "print(train_iter[1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5513914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=', 'Valkyria', 'Chronicles', 'III', '=']\n",
      "('=', 'Valkyria')\n",
      "('=', 'Chronicles')\n",
      "('Valkyria', '=')\n",
      "('Valkyria', 'Chronicles')\n",
      "('Valkyria', 'III')\n",
      "('Chronicles', '=')\n",
      "('Chronicles', 'Valkyria')\n",
      "('Chronicles', 'III')\n",
      "('Chronicles', '=')\n",
      "('III', 'Valkyria')\n",
      "\n",
      " ############################ \n",
      "\n",
      "(['Valkyria', 'Chronicles'], '=')\n",
      "(['=', 'Chronicles', 'III'], 'Valkyria')\n",
      "(['=', 'Valkyria', 'III', '='], 'Chronicles')\n",
      "(['Valkyria', 'Chronicles', '='], 'III')\n",
      "(['Chronicles', 'III'], '=')\n",
      "(['no', 'Valkyria'], 'Senjō')\n",
      "(['Senjō', 'Valkyria', '3'], 'no')\n",
      "(['Senjō', 'no', '3', ':'], 'Valkyria')\n",
      "(['no', 'Valkyria', ':', '<unk>'], '3')\n",
      "(['Valkyria', '3', '<unk>', 'Chronicles'], ':')\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "train_tokens = [tokenize(item) for item in train_iter]\n",
    "\n",
    "def create_skip_gram_pairs(tokens, window_size=2):\n",
    "    pairs = []\n",
    "    for sentence in tokens:\n",
    "        for target_index, target_word in enumerate(sentence):\n",
    "            for context_index in range(\n",
    "                max(0, target_index - window_size),\n",
    "                min(len(sentence), target_index + window_size + 1)\n",
    "            ):\n",
    "                if target_index != context_index:\n",
    "                    pairs.append((target_word, sentence[context_index]))\n",
    "    return pairs\n",
    "\n",
    "skip_gram_pairs = create_skip_gram_pairs(train_tokens)\n",
    "\n",
    "# Sample output of Skip-Gram pairs\n",
    "for pair in skip_gram_pairs[:10]:\n",
    "    print(pair)\n",
    "    \n",
    "print('\\n ############################ \\n')\n",
    "   \n",
    "#Pairs where the context is a list of words, and the target word is the word you're \n",
    "#trying to predict based on the context \n",
    "\n",
    "def create_cbow_pairs(tokens, window_size=2):\n",
    "    pairs = []\n",
    "    for sentence in tokens:\n",
    "        for target_index, target_word in enumerate(sentence):\n",
    "            context = []\n",
    "            for context_index in range(\n",
    "                max(0, target_index - window_size),\n",
    "                min(len(sentence), target_index + window_size + 1)\n",
    "            ):\n",
    "                if target_index != context_index:\n",
    "                    context.append(sentence[context_index])\n",
    "            if context:  # Ensure there is at least one context word\n",
    "                pairs.append((context, target_word))\n",
    "    return pairs\n",
    "\n",
    "cbow_pairs = create_cbow_pairs(train_tokens)\n",
    "\n",
    "# Sample output of CBOW pairs\n",
    "for pair in cbow_pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "159c33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  2  2 ...  0  0  0]\n",
      " [ 2  4  6 ...  0  0  0]\n",
      " [ 2  3  4 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " the word playing appears in the context of video, 0 times\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "window_size = 5  \n",
    "min_word_frequency = 5  \n",
    "\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "index = 0\n",
    "\n",
    "train_tokens_sm = train_tokens[:10]\n",
    "\n",
    "for tokens in train_tokens_sm:\n",
    "    if tokens != []:\n",
    "        for token in tokens:\n",
    "            if token not in word_to_index:\n",
    "                word_to_index[token] = index\n",
    "                index_to_word[index] = token\n",
    "                index += 1\n",
    "                \n",
    "#print(word_to_index)\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "#print(vocab_size)\n",
    "co_occurrence_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int64)\n",
    "\n",
    "for tokens in train_tokens_sm:\n",
    "    if tokens != []:\n",
    "        for target_word in tokens:\n",
    "            if target_word in word_to_index:\n",
    "                target_word_index = word_to_index[target_word]\n",
    "                for context_index in range(\n",
    "                        max(0, target_word_index - window_size),\n",
    "                        min(len(tokens), target_word_index + window_size + 1)):\n",
    "                    if target_word_index != context_index and tokens[context_index] in word_to_index:\n",
    "                        context_word_index = word_to_index[tokens[context_index]]\n",
    "\n",
    "                        co_occurrence_matrix[target_word_index][context_word_index] += 1\n",
    "        \n",
    "        \n",
    "\n",
    "print(co_occurrence_matrix)\n",
    "index1 = 30\n",
    "index2 = 31\n",
    "print(f' the word {index_to_word[index1]} appears in the context of {index_to_word[index2]}, {co_occurrence_matrix[index1][index2]} times')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
