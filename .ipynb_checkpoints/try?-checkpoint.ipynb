{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f283ed4-3b74-4b8a-8d4e-5593445a9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'simple', 'example', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def simple_tokenizer(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Example usage:\n",
    "text_example = \"This is a, simple example sentence.\"\n",
    "tokens_example = simple_tokenizer(text_example)\n",
    "print(tokens_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95908a5b-58b1-4d5b-9f7d-9ff456d460d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import string\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "allowed_chars = string.ascii_lowercase + ' '\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, file_en, file_es,max_length):\n",
    "        self.sentences_en = self.load_sentences(file_en)\n",
    "        self.sentences_es = self.load_sentences(file_es)\n",
    "\n",
    "        self.tokenizer_es = self.tokenizer\n",
    "        self.tokenizer_en = self.tokenizer\n",
    "\n",
    "        self.vocab_en = self.build_vocab(self.sentences_en)\n",
    "        self.vocab_es = self.build_vocab(self.sentences_es)\n",
    "\n",
    "        self.archivo_ingles = file_en\n",
    "        self.archivo_espanol = file_es\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def build_vocab(self, sentences):\n",
    "        words = set()\n",
    "        for sentence in sentences:\n",
    "            words.update(self.tokenizer(sentence))\n",
    "        vocab = {word: idx for idx, word in enumerate(words)}\n",
    "        return vocab\n",
    "\n",
    "    def load_sentences(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return [line.strip() for line in file]\n",
    "\n",
    "    def sample(self):\n",
    "        index = random.randint(0, len(self.sentences_en) - 1)\n",
    "        return self.string_to_tensor(self.sentences_en[index],self.vocab_en), self.string_to_tensor(self.sentences_es[index],self.vocab_es)\n",
    "\n",
    "    def batch(self, n):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for _ in range(n):\n",
    "            input, output = self.sample()\n",
    "            inputs.append(input)\n",
    "            outputs.append(output)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def string_to_tensor(self, s, vocab):\n",
    "        indices = [vocab.get(token, len(vocab) - 1) for token in self.tokenizer(s)] + [vocab.get('<pad>', len(vocab) - 1)]\n",
    "        # Ensure the tensor has a fixed length by padding or truncating\n",
    "        indices = indices[:self.max_length] + [0] * max(0, self.max_length - len(indices))\n",
    "        res = torch.tensor(indices)\n",
    "        return res\n",
    "\n",
    "    def batch_to_tensor(self, n):\n",
    "        seq_in = []\n",
    "        seq_out = []\n",
    "        inputs, outputs = self.batch(n)\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            seq_in.append(self.string_to_tensor(input, self.vocab_en))\n",
    "            seq_out.append(self.string_to_tensor(output, self.vocab_es))\n",
    "        return pad_sequence(seq_in, batch_first=True), pad_sequence(seq_out, batch_first=True)\n",
    "\n",
    "    def tokens_to_tensor(self, tokens, vocab):\n",
    "        return torch.stack([torch.tensor(vocab.get(token, len(vocab)-1)) for token in tokens])\n",
    "\n",
    "    def tensor_to_string(self, tensor, vocab, is_tensor=False): #############################################\n",
    "        if is_tensor:\n",
    "            indices = tensor.view(-1).tolist()\n",
    "        else:\n",
    "            indices = tensor\n",
    "        return ''.join([list(vocab.keys())[int(idx)] for idx in indices])\n",
    "  \n",
    "    def tokens_to_indices(self, tokens, vocab):\n",
    "        return [vocab.stoi[token] for token in tokens] + [vocab.stoi['<pad>']]\n",
    "\n",
    "    def get_output_lengths(self, n):\n",
    "        _, outputs = self.batch(n)\n",
    "        return [len(seq) for seq in outputs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_en)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.sentences_en[idx], self.sentences_es[idx]\n",
    "        tokens_ingles = self.tokenizer_en(item[0])\n",
    "        tokens_espanol = self.tokenizer_es(item[1])\n",
    "\n",
    "        tokens_ingles = tokens_ingles + ['<eos>']\n",
    "        tokens_espanol = ['<sos>'] + tokens_espanol + ['<eos>']\n",
    "\n",
    "        if not tokens_ingles or not tokens_espanol:\n",
    "            return torch.zeros(1, len(self.vocab_en)), torch.zeros(1, len(self.vocab_es))\n",
    "    \n",
    "        tensor_ingles = self.string_to_tensor(item[0], self.vocab_en)\n",
    "        tensor_espanol = self.string_to_tensor(item[1], self.vocab_es)\n",
    "\n",
    "        indices_ingles = [self.vocab_en.get(token, len(self.vocab_en)-1) for token in tokens_ingles] + [self.vocab_en.get('<pad>', len(self.vocab_en)-1)]\n",
    "        indices_espanol = [self.vocab_es.get(token, len(self.vocab_es)-1) for token in tokens_espanol] + [self.vocab_es.get('<pad>', len(self.vocab_es)-1)]\n",
    "\n",
    "        return tensor_ingles, tensor_espanol\n",
    "\n",
    "    def tokenizer(self, text):\n",
    "        # Remove punctuation\n",
    "        if isinstance(text, torch.Tensor):\n",
    "            # Convert tensor to string\n",
    "            text = self.tensor_to_string(text, self.vocab_en)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = text.lower().split()\n",
    "        return tokens\n",
    "        \n",
    "    def add_sos_eos_unk_pad(self, vocabulary):\n",
    "        words = vocabulary.itos\n",
    "        vocab = vocabulary.stoi\n",
    "        embedding_matrix = vocabulary.vectors\n",
    "\n",
    "        # Tokens especiales\n",
    "        sos_token = '<sos>'\n",
    "        eos_token = '<eos>'\n",
    "        pad_token = '<pad>'\n",
    "        unk_token = '<unk>'\n",
    "\n",
    "        # Inicializamos los vectores para los tokens especiales, por ejemplo, con ceros\n",
    "        sos_vector = torch.full((1, embedding_matrix.shape[1]), 1.)\n",
    "        eos_vector = torch.full((1, embedding_matrix.shape[1]), 2.)\n",
    "        pad_vector = torch.zeros((1, embedding_matrix.shape[1]))\n",
    "        unk_vector = torch.full((1, embedding_matrix.shape[1]), 3.)\n",
    "\n",
    "        # Añade los vectores al final de la matriz de embeddings\n",
    "        embedding_matrix = torch.cat((embedding_matrix, sos_vector, eos_vector, unk_vector, pad_vector), 0)\n",
    "\n",
    "        # Añade los tokens especiales al vocabulario\n",
    "        vocab[sos_token] = len(vocab)\n",
    "        vocab[eos_token] = len(vocab)\n",
    "        vocab[pad_token] = len(vocab)\n",
    "        vocab[unk_token] = len(vocab)\n",
    "\n",
    "        words.append(sos_token)\n",
    "        words.append(eos_token)\n",
    "        words.append(pad_token)\n",
    "        words.append(unk_token)\n",
    "\n",
    "        vocabulary.itos = words\n",
    "        vocabulary.stoi = vocab\n",
    "        vocabulary.vectors = embedding_matrix\n",
    "\n",
    "        default_stoi = defaultdict(lambda : len(vocabulary)-1, vocabulary.stoi)\n",
    "        vocabulary.stoi = default_stoi\n",
    "        return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c085445-53f0-47cf-9180-626fbf7058b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class Translation(Dataset):\n",
    "    def __init__(self, source_file, target_file):\n",
    "        self.ingles = []\n",
    "        self.espanol = []\n",
    "        self.tokenizer_es = get_tokenizer(\"spacy\", language=\"es_core_news_md\")\n",
    "        self.tokenizer_en = get_tokenizer(\"spacy\", language=\"en_core_web_md\")\n",
    "        self.vocab_es = torchtext.vocab.FastText(language='es', unk_init=torch.Tensor.normal_)  # <-- Mirar esto para ver si añadir el token <unk> al vocabulario\n",
    "        self.vocab_en = torchtext.vocab.FastText(language='en', unk_init=torch.Tensor.normal_)\n",
    "\n",
    "        self.vocab_en = self.add_sos_eos_unk_pad(self.vocab_en)\n",
    "        self.vocab_es = self.add_sos_eos_unk_pad(self.vocab_es)\n",
    "\n",
    "        self.archivo_ingles = source_file\n",
    "        self.archivo_espanol = target_file\n",
    "\n",
    "        # Leer el conjunto de datos\n",
    "        for ingles, espanol in self.read_translation():\n",
    "            self.ingles.append(ingles)\n",
    "            self.espanol.append(espanol)\n",
    "    def add_sos_eos_unk_pad(self, vocabulary):\n",
    "        words = vocabulary.itos\n",
    "        vocab = vocabulary.stoi\n",
    "        embedding_matrix = vocabulary.vectors\n",
    "\n",
    "        # Tokens especiales\n",
    "        sos_token = '<sos>'\n",
    "        eos_token = '<eos>'\n",
    "        pad_token = '<pad>'\n",
    "        unk_token = '<unk>'\n",
    "\n",
    "        # Inicializamos los vectores para los tokens especiales, por ejemplo, con ceros\n",
    "        sos_vector = torch.full((1, embedding_matrix.shape[1]), 1.)\n",
    "        eos_vector = torch.full((1, embedding_matrix.shape[1]), 2.)\n",
    "        pad_vector = torch.zeros((1, embedding_matrix.shape[1]))\n",
    "        unk_vector = torch.full((1, embedding_matrix.shape[1]), 3.)\n",
    "\n",
    "        # Añade los vectores al final de la matriz de embeddings\n",
    "        embedding_matrix = torch.cat((embedding_matrix, sos_vector, eos_vector, unk_vector, pad_vector), 0)\n",
    "\n",
    "        # Añade los tokens especiales al vocabulario\n",
    "        vocab[sos_token] = len(vocab)\n",
    "        vocab[eos_token] = len(vocab)\n",
    "        vocab[pad_token] = len(vocab)\n",
    "        vocab[unk_token] = len(vocab)\n",
    "\n",
    "        words.append(sos_token)\n",
    "        words.append(eos_token)\n",
    "        words.append(pad_token)\n",
    "        words.append(unk_token)\n",
    "\n",
    "        vocabulary.itos = words\n",
    "        vocabulary.stoi = vocab\n",
    "        vocabulary.vectors = embedding_matrix\n",
    "\n",
    "        default_stoi = defaultdict(lambda : len(vocabulary)-1, vocabulary.stoi)\n",
    "        vocabulary.stoi = default_stoi\n",
    "        return vocabulary\n",
    "        \n",
    "\n",
    "    def read_translation(self):\n",
    "        with open(self.archivo_ingles, 'r', encoding='utf-8') as f_ingles, open(self.archivo_espanol, 'r', encoding='utf-8') as f_espanol:\n",
    "            for oracion_ingles, oracion_espanol in zip(f_ingles, f_espanol):\n",
    "                yield oracion_ingles.strip().lower(), oracion_espanol.strip().lower()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ingles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ingles[idx], self.espanol[idx]\n",
    "        tokens_ingles = self.tokenizer_en(item[0])\n",
    "        tokens_espanol = self.tokenizer_es(item[1])\n",
    "\n",
    "        tokens_ingles = tokens_ingles + ['<eos>']\n",
    "        tokens_espanol = ['<sos>'] + tokens_espanol + ['<eos>']\n",
    "\n",
    "        if not tokens_ingles or not tokens_espanol:\n",
    "            return torch.zeros(1, 300), torch.zeros(1, 300)\n",
    "            # raise RuntimeError(\"Una de las muestras está vacía.\")\n",
    "    \n",
    "        tensor_ingles = self.vocab_en.get_vecs_by_tokens(tokens_ingles)\n",
    "        tensor_espanol = self.vocab_es.get_vecs_by_tokens(tokens_espanol)\n",
    "\n",
    "        indices_ingles = [self.vocab_en.stoi[token] for token in tokens_ingles] + [self.vocab_en.stoi['<pad>']]\n",
    "        indices_espanol = [self.vocab_es.stoi[token] for token in tokens_espanol] + [self.vocab_es.stoi['<pad>']]\n",
    "\n",
    "        return tensor_ingles, tensor_espanol, indices_ingles, indices_espanol\n",
    "        \n",
    "def collate_fn(batch):\n",
    "    ingles_batch, espanol_batch= zip(*batch)\n",
    "    ingles_batch = pad_sequence(ingles_batch, batch_first=True, padding_value=0)\n",
    "    espanol_batch = pad_sequence(espanol_batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return ingles_batch, espanol_batch   \n",
    "        \n",
    "def collate_fn3(batch):\n",
    "    ingles_batch, espanol_batch, ingles_seqs, espanol_seqs = zip(*batch)\n",
    "    ingles_batch = pad_sequence(ingles_batch, batch_first=True, padding_value=0)\n",
    "    espanol_batch = pad_sequence(espanol_batch, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Calcular la longitud máxima de la lista de listas de índices\n",
    "    pad = espanol_seqs[0][-1]  # token <pad>\n",
    "    max_len = max([len(l) for l in espanol_seqs])\n",
    "    for seq in espanol_seqs:\n",
    "        seq += [pad]*(max_len-len(seq))\n",
    "        \n",
    "    return ingles_batch, espanol_batch, ingles_seqs, espanol_seqs\n",
    "\n",
    "\n",
    "def collate_fn5(batch):\n",
    "    # Sort the batch by the length of the English sequences for efficient padding\n",
    "    batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    # Separate the elements of the batch\n",
    "    tensors_ingles, tensors_espanol, indices_ingles, indices_espanol = zip(*batch)\n",
    "\n",
    "    # Pad the sequences to have the same length\n",
    "    # Assuming tensors_ingles and tensors_espanol are lists of tensors\n",
    "    # Find the maximum lengths in both sequences\n",
    "    max_length_ingles = max(seq.size(0) for seq in tensors_ingles)\n",
    "    max_length_espanol = max(seq.size(0) for seq in tensors_espanol)\n",
    "    max_length = max(max_length_ingles,max_length_espanol)\n",
    "    print(max_length_ingles)\n",
    "    print(max_length_espanol)\n",
    "    print(max_length)\n",
    "    \n",
    "    # Pad both sequences to the maximum length\n",
    "    padded_ingles = pad_sequence([torch.cat([seq, torch.zeros(max_length - len(seq), input_dim)]) for seq in tensors_ingles], batch_first=True)\n",
    "\n",
    "    #padded_ingles = pad_sequence([F.pad(seq, pad=(0, max_length - seq.size(0))) for seq in tensors_ingles], batch_first=True)\n",
    "    padded_espanol = pad_sequence([F.pad(seq, pad=(0, max_length - seq.size(0))) for seq in tensors_espanol], batch_first=True)\n",
    "    \n",
    "    print(padded_ingles.shape)\n",
    "    print(padded_espanol.shape)\n",
    "\n",
    "    # Convert indices to PyTorch tensors\n",
    "    tensor_indices_ingles = torch.tensor(indices_ingles, dtype=torch.long)\n",
    "    tensor_indices_espanol = torch.tensor(indices_espanol, dtype=torch.long)\n",
    "\n",
    "    return padded_ingles, padded_espanol, tensor_indices_ingles, tensor_indices_espanol\n",
    "\n",
    "def collate_fn7(batch):\n",
    "    tensors_ingles, tensors_espanol, _, _ = zip(*batch)\n",
    "\n",
    "    # Convert sequences to tensors\n",
    "    #tensors_ingles = [translation.string_to_tensor(seq, translation.vocab_en) for seq in inputs]\n",
    "    #tensors_espanol = [translation.string_to_tensor(seq, translation.vocab_es) for seq in outputs]\n",
    "\n",
    "    # Find the maximum lengths in both sequences\n",
    "    max_length_ingles = max(seq.size(0) for seq in tensors_ingles)\n",
    "    max_length_espanol = max(seq.size(0) for seq in tensors_espanol)\n",
    "    max_length = max(max_length_ingles,max_length_espanol)\n",
    "    \n",
    "    print(tensors_ingles[1].shape)\n",
    "    print(tensors_espanol[1].shape)\n",
    "    \n",
    "    # Pad both sequences to the maximum length\n",
    "    padded_ingles = pad_sequence([F.pad(seq, pad=(0, max_length - seq.size(0))) for seq in tensors_ingles], batch_first=True)\n",
    "    padded_espanol = pad_sequence([F.pad(seq, pad=(0, max_length - seq.size(0))) for seq in tensors_espanol], batch_first=True)\n",
    "\n",
    "    print(padded_ingles.shape)\n",
    "    print(padded_espanol.shape)\n",
    "\n",
    "    return padded_ingles, padded_espanol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad9e453-cc48-491d-8b68-00a3fcf13626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.rnn(x, hidden)\n",
    "        return output, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3375fe34-3a6b-47c2-9bb2-8bb1228d1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, attention_type='dot'):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.attention_type = attention_type\n",
    "        self.encoder_hidden_states = None\n",
    "\n",
    "    def assign_encoder_hidden_states(self, hidden_states):\n",
    "        self.encoder_hidden_states = hidden_states\n",
    "\n",
    "    def calculate_score(self, decoder_hidden_states):\n",
    "        if self.attention_type == 'dot':\n",
    "            # Dot product attention\n",
    "            print(decoder_hidden_states.shape)\n",
    "            print(self.encoder_hidden_states.transpose(1, 2).shape)\n",
    "            return torch.bmm(decoder_hidden_states, self.encoder_hidden_states.transpose(1, 2))\n",
    "\n",
    "        #decoder_hidden_states has shape (batch_size, seq_len, hidden_size) and \n",
    "        #self.encoder_hidden_states has shape (batch_size, hidden_size, seq_len)\n",
    "        \n",
    "        elif self.attention_type == 'general':\n",
    "            # General (linear) attention\n",
    "            W = nn.Linear(in_features=decoder_hidden_states.size(-1), out_features=self.encoder_hidden_states.size(-1), bias=False)\n",
    "            decoder_hidden_states = W(decoder_hidden_states)\n",
    "            return torch.bmm(decoder_hidden_states, self.encoder_hidden_states.transpose(1, 2))\n",
    "        elif self.attention_type == 'concat':\n",
    "            # Concatenation attention\n",
    "            W = nn.Linear(in_features=decoder_hidden_states.size(-1) + self.encoder_hidden_states.size(-1), out_features=1, bias=False)\n",
    "            combined_states = torch.cat((decoder_hidden_states, self.encoder_hidden_states), dim=-1)\n",
    "            energy = torch.tanh(W(combined_states))\n",
    "            return energy.transpose(1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid attention type. Choose 'dot', 'general', or 'concat'.\")\n",
    "\n",
    "    def source_context(self, decoder_hidden_states):\n",
    "        energy = self.calculate_score(decoder_hidden_states)\n",
    "\n",
    "        # Apply softmax along the source sequence dimension\n",
    "        attention_weights = F.softmax(energy, dim=-1)\n",
    "\n",
    "        # Calculate the context vector by taking the weighted sum of encoder hidden states\n",
    "        context_vector = torch.bmm(attention_weights, self.encoder_hidden_states)\n",
    "\n",
    "        return context_vector #attention_weights, context_vector\n",
    "\n",
    "    def forward(self, decoder_hidden_state):\n",
    "        return self.source_context(decoder_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7690bde4-c484-445f-8f09-7353f9d3b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.rnn(x, (hidden, cell))\n",
    "        return output, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbc7864-7af6-4a7c-9046-54787e761629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.attention = LuongAttention(attention_type='dot')\n",
    "        self.decoder = Decoder(hidden_size, hidden_size)\n",
    "        self.reduce_dimension = nn.Linear(hidden_size, output_size)\n",
    "        self.output = nn.Linear(output_size, output_size)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def forward(self, input, hidden=None):\n",
    "        output_enc, (hn_enc, cn_enc) = self.encoder(input, hidden)\n",
    "        self.attention.assign_encoder_hidden_states(output_enc)\n",
    "        #latent_tensor = hn_enc[0].unsqueeze(1).repeat(1, input.size(1), 1)  \n",
    "        latent_tensor = hn_enc.unsqueeze(1).repeat(1, input.size(1), 1)\n",
    "        print(latent_tensor.shape)\n",
    "        print(hn_enc.shape)\n",
    "        print(cn_enc.shape)\n",
    "        out_dec, (_, _) = self.decoder(latent_tensor, hn_enc, cn_enc)\n",
    "        print(5)\n",
    "        attention_output = self.attention(out_dec)\n",
    "\n",
    "        reduced_output = self.reduce_dimension(out_dec)\n",
    "        attention_output = attention_output[:, :, :reduced_output.size(2)]\n",
    "\n",
    "        return self.output(reduced_output * attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86ef096-91ce-4f62-bd4d-d7a1139f9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "archivo_ingles = 'mock.en'\n",
    "archivo_espanol = 'mock.es'\n",
    "max_length = 10  # Define your desired sequence length\n",
    "translator = Translator('mock.en', 'mock.es',max_length)\n",
    "\n",
    "# Parámetros\n",
    "input_dim = 512\n",
    "output_dim = translator.get_output_lengths(n=1)[0]\n",
    "print(output_dim)\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a64a50-521d-4368-8c6f-29fd137f5d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### CARGAMENTO #####\n",
      "torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "###### INICIALIZACION MODELO #####\n",
      "###### ENTRENAMIENTO #####\n",
      "torch.Size([1, 10, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m###### ENTRENAMIENTO #####\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, n_epochs, batch_size, train_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m padded_tensor1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,max_length \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     15\u001b[0m padded_tensor2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(y, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,max_length \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_tensor1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, padded_tensor2)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(hn_enc\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(cn_enc\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 19\u001b[0m out_dec, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhn_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcn_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(out_dec)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, hidden, cell)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden, cell):\n\u001b[0;32m----> 7\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, (hidden, cell)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:866\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    864\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 3-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 866\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model, optimizer, loss_fn, n_epochs, batch_size, train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y= batch  # The collate_fn returns four elements, but we only need x and y for training\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Determine the maximum sequence length\n",
    "            max_length = max(x.size(1), y.size(1))\n",
    "\n",
    "            padded_tensor1 = F.pad(x, (0, 0,max_length - x.size(1), 0))\n",
    "            padded_tensor2 = F.pad(y, (0, 0,max_length - y.size(1), 0))\n",
    "            \n",
    "            y_pred = y_pred = model(padded_tensor1.float())\n",
    "\n",
    "            loss = loss_fn(y_pred, padded_tensor2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss))\n",
    "        history.append(total_loss)\n",
    "\n",
    "# Assuming train_dataset and eval_dataset are instances of Translation\n",
    "print('###### CARGAMENTO #####')\n",
    "\n",
    "#train_dataset = Translation(source_file='path/to/source_file.txt', target_file='path/to/target_file.txt')\n",
    "train_dataset = Translator('mock.en', 'mock.es',max_length)\n",
    "eval_dataset = Translator('mockeval.en', 'mockeval.es',max_length)\n",
    "\n",
    "padded_inputs, padded_outputs = train_dataset.batch_to_tensor(5)\n",
    "print(padded_inputs.shape)\n",
    "print(padded_outputs.shape)\n",
    "\n",
    "# Create DataLoaders using the collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "print('###### INICIALIZACION MODELO #####')\n",
    "model = Seq2Seq(input_dim, hidden_size, output_dim)\n",
    "history = []\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "print('###### ENTRENAMIENTO #####')\n",
    "train(model, optimizer, loss_fn, num_epochs, batch_size, train_loader)\n",
    "plt.plot(history, label='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfde69-951b-4b8d-a968-f0f2ef4f7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, n, eval_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            x, y= batch  # The collate_fn returns four elements, but we only need x and y for evaluation\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            for i in range(min(n, len(x))):\n",
    "            #    print(\"Predicted:\", translation.tensor_to_string(y_pred[i],translation.vocab_es))\n",
    "            #    print(\"Actual:\", translation.tensor_to_string(y[i],translation.vocab_es))\n",
    "            #    print()\n",
    "                #print(\"Predicted:\", y_pred[i])\n",
    "                #print(\"Actual:\", translator.tensor_to_string(y[i],translator.vocab_es))\n",
    "                predicted_word = translator.tensor_to_string(y_pred, translation.vocab_es, is_tensor=True)\n",
    "                print(\"Predicted word:\", predicted_word)\n",
    "evaluate(model, 5, eval_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90ee52-a9cf-46a3-ba20-c939ab88a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_enc = torch.rand(1, 512)\n",
    "print(hn_enc.shape)\n",
    "#hn_enc = torch.rand(batch_size, seq_len, hidden_size)\n",
    "latent_tensor = hn_enc.unsqueeze(1).repeat(1, input_dim, 1)\n",
    "print(latent_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00a072-3644-4aa7-8170-726e79512d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
